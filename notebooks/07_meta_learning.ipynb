{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9100,
     "status": "ok",
     "timestamp": 1740643451843,
     "user": {
      "displayName": "David",
      "userId": "15621012621986902730"
     },
     "user_tz": -60
    },
    "id": "JCUz9iB34Ivq",
    "outputId": "81a27999-4197-4130-b556-ede1995af411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Google Colab session.\n",
      "/mnt/c/Users/DavidHanny/OneDrive - IT U interdisciplinary transformation university austria/Documents/projects/papers/2025a_relevance_classification_2.0\n"
     ]
    }
   ],
   "source": [
    "# activate autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# check if session is in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print('Google Colab session!')\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print('Not a Google Colab session.')\n",
    "\n",
    "# add src path to the notebook\n",
    "import os\n",
    "import sys\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PROJECT_ROOT: str = '/content/drive/MyDrive/papers/2025b_relevance_2.0'\n",
    "    !pip install contextily esda deep-translator h3pandas h3~=3.0 datasets optuna setfit\n",
    "else:\n",
    "    PROJECT_ROOT: str = os.path.dirname(os.path.abspath(os.path.dirname(\"__file__\")))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(os.path.join(PROJECT_ROOT))\n",
    "print(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TtpHvm54Ivt"
   },
   "source": [
    "# Meta Learning\n",
    "Okay, so instead of simply concatenating representations or in-context learning, we can also try to join the features with meta learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 31223,
     "status": "ok",
     "timestamp": 1740643483068,
     "user": {
      "displayName": "David",
      "userId": "15621012621986902730"
     },
     "user_tz": -60
    },
    "id": "9dlg4br24Ivu",
    "outputId": "32f3c8e1-a819-470a-eba8-8d91590c8ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/DavidHanny/OneDrive - IT U interdisciplinary transformation university austria/Documents/projects/papers/2025a_relevance_classification_2.0/data\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, root_mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from src.model_training.classification_head import optimise_model, evaluate_model\n",
    "from src.model_training.bert import train_classifier, extract_probabilities\n",
    "tqdm.pandas()\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# surpress ConvergenceWarnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "\n",
    "# set data path\n",
    "DATA_PATH: str = os.path.join(PROJECT_ROOT, 'data')\n",
    "RESULTS_PATH: str = os.path.join(PROJECT_ROOT, 'results')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# set pytorch device\n",
    "device: str = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training Data\n",
    "First, we need to prepare our training and evaluation data that we will use throughout the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class encodings: ['Not related', 'Related but not relevant', 'Related and relevant']\n",
      "(3659, 45)\n",
      "(915, 45)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "message_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "use_case",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tweet_lang",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "geometry",
         "rawType": "geometry",
         "type": "unknown"
        },
        {
         "name": "photo_url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "text_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "related",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "text_translated",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "prev_category",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "gpt_4o_mini_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "human_label_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "other_disaster",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "geom_height",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "human_label_20km",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "human_label_50km",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "human_label_100km",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "event_distance_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "event_distance_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "event_distance_h_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_1km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_5km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_10km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_50km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_10000km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "emotion_probs",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentiment_probs",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "event_encoding",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "event_type_encoding",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lon_centre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat_centre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sphere_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sphere_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sphere_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "int_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "valid",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "event_distance_km_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "event_distance_h_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_1km_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_10km_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_50km_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_disaster_tweets_10000km_norm",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ca06a4bc-484f-40b4-ad2f-59b75a8624cd",
       "rows": [
        [
         "0",
         "1.2968e+18",
         "2020-08-21 13:40:45",
         "California 🔥",
         "Closed due to the czu august lightning complex fire in #Pescadero on CA-1 SB between Gazos Crk Rd and Davenport Landing Rd #BayArea #Traffic http",
         null,
         "POINT (-122.3611 37.16663)",
         null,
         "Closed due to the czu august lightning complex fire in #Pescadero on CA-1 SB between Gazos Crk Rd and Davenport Landing Rd #BayArea #Traffic https://t.co/pmlOhZuRWR",
         "1",
         "-13621175.34",
         "4462358.381",
         null,
         null,
         "Related and relevant",
         "Related but not relevant",
         null,
         "0.0",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "2.2606127727697163",
         "0.0",
         "0.0",
         "1.0",
         "2.0",
         "2.0",
         "119.0",
         "859.0",
         "[0.11253574 0.81187576 0.02359341 0.05199511]",
         "[0.83850318 0.14529616 0.01620074]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "1",
         "True",
         "-0.4575314694590643",
         "-0.09912034494341272",
         "-0.3709970810135179",
         "-0.4513174522227094",
         "0.7587019090234153",
         "1.366236084976255"
        ],
        [
         "1",
         "1.4171e+18",
         "2021-07-19 12:23:18",
         "Germany 🌊",
         "Mich beunruhigt nichts mehr.Wir sorgen persönlich vor.Droht Sturm und Tornado räume ich Dachgeschoss und suche Schutz. Bei Hochwasser umgekehrt.Gegen Blackout Photovoltaikinsel und Wasserfilter für Brunnen. Vorräte wie Prepper. Reservekanister bei Dflaute. http",
         "de",
         "POINT (12.226706198159917 51.849228032882735)",
         null,
         "Mich beunruhigt nichts mehr.Wir sorgen persönlich vor.Droht Sturm und Tornado räume ich Dachgeschoss und suche Schutz. Bei Hochwasser umgekehrt.Gegen Blackout Photovoltaikinsel und Wasserfilter für Brunnen. Vorräte wie Prepper. Reservekanister bei Dflaute. https://t.co/eTWLT8mqmG",
         "1",
         "1361556.15",
         "6773463.005",
         "Nothing worries me anymore. We take personal precautions. If there is a threat of a storm or tornado, I clear the attic and seek shelter. The opposite happens when there is flooding. To prevent blackouts, I have a photovoltaic island and a water filter for the well. Stock up like a prepper. Reserve canisters in case of a calm. http",
         "4 - nicht relevant",
         "Related and relevant",
         "Related but not relevant",
         null,
         "42735.26172732003",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "310.10338950332516",
         "60.388333333333335",
         "60.388333333333335",
         "21.0",
         "21.0",
         "21.0",
         "32.0",
         "2239.0",
         "[0.0048289  0.98765332 0.0044863  0.0030315 ]",
         "[0.80421221 0.17226584 0.02352202]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "1.30080859463964",
         "0.09560924212299636",
         "0.36279306555029883",
         "0.052028436165705516",
         "-0.4674722092878205",
         "1.5108342968919877"
        ],
        [
         "2",
         "1.34127e+18",
         "2020-12-22 06:29:24",
         "California 🔥",
         "The view out my kitchen window of the massive fire in North Hollywood right now http",
         null,
         "POINT (-118.41190649999999 34.02069278261392)",
         null,
         "The view out my kitchen window of the massive fire in North Hollywood right now https://t.co/cGcFMBKtQH",
         "1",
         "-13181553.14",
         "4031673.022",
         null,
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "84951.32051535742",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "54.49",
         "54.49",
         "23.0",
         "24.0",
         "25.0",
         "46.0",
         "115.0",
         "[0.56315535 0.26214159 0.14971597 0.0249871 ]",
         "[0.09706938 0.39531016 0.50762045]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "2",
         "True",
         "-0.7146476346465247",
         "0.7728619202569351",
         "0.7985912484346517",
         "0.5276911185510109",
         "-0.17229218161640833",
         "-0.7192904525285823"
        ],
        [
         "3",
         "1.32086e+18",
         "2020-10-26 22:49:26",
         "California 🔥",
         "@user @user @user I love 1/2 miles from Anaheim Hills Elementary fire watch truck was in front of my house for a while. 🙏🙏",
         null,
         "POINT (-117.85108899999997 33.84274820410713)",
         null,
         "@ZestForLifeNow @City_of_Anaheim @AnaheimFire I love 1/2 miles from Anaheim Hills Elementary fire watch truck was in front of my house for a while. 🙏🙏",
         "1",
         "-13119123.22",
         "4007724.114",
         null,
         null,
         "Related but not relevant",
         "Related and relevant",
         null,
         "14461.639973721001",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "0.0",
         "0.0",
         "6.0",
         "8.0",
         "11.0",
         "106.0",
         "273.0",
         "[1.63071696e-03 6.34028809e-04 9.95905638e-01 1.82960578e-03]",
         "[0.04218552 0.12851283 0.82930171]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "2",
         "True",
         "-0.7146476346465247",
         "-0.09912034494341272",
         "-0.10518155159347937",
         "-0.06822714191994927",
         "0.5929084408272823",
         "-0.27639637601545824"
        ],
        [
         "4",
         "1.29605e+18",
         "2020-08-19 11:26:50",
         "California 🔥",
         "Someone fucking set off my apartment building’s fire alarm at 4:30 am 😭😭😭",
         null,
         "POINT (-118.41190649999999 34.02069278261392)",
         null,
         "Someone fucking set off my apartment building’s fire alarm at 4:30 am 😭😭😭",
         "1",
         "-13181553.14",
         "4031673.022",
         null,
         null,
         "Not related",
         "Not related",
         null,
         "84951.32051535742",
         "Not related",
         "Not related",
         "Not related",
         "0.0",
         "59.44722222222222",
         "59.44722222222222",
         "54.0",
         "55.0",
         "57.0",
         "138.0",
         "459.0",
         "[0.02320865 0.00958194 0.96253401 0.00467542]",
         "[0.04973024 0.36927381 0.58099592]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "-0.7146476346465247",
         "0.8521904183746601",
         "2.4466475308388906",
         "1.8897899996274912",
         "1.0010154394639172",
         "0.24498525836075108"
        ],
        [
         "5",
         "1.61493e+18",
         "2023-01-16 10:37:32",
         "Turkey 🪨",
         "Tabi okumuş adam ... diyememiş ekonomik tsunami geliyor demiş!..",
         "tr",
         "POINT (38.80034749095737 37.142790909321796)",
         null,
         "Tabi okumuş adam ... diyememiş ekonomik tsunami geliyor demiş!..",
         "1",
         "4319309.956",
         "4459597.839",
         "Of course, the educated man couldn't say... he said an economic tsunami was coming!..",
         null,
         "Not related",
         "Not related",
         null,
         "11673.257698069327",
         "Not related",
         "Not related",
         "Not related",
         "83.11502925611143",
         "-496.0200847222222",
         "496.0200847222222",
         "3.0",
         "3.0",
         "3.0",
         "5.0",
         "313.0",
         "[0.04806507 0.0572568  0.00496547 0.88971269]",
         "[0.86942148 0.09719779 0.03338076]",
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "0",
         "True",
         "-0.7487302112022973",
         "-1.687296476420272",
         "-0.43111237772467786",
         "-0.5503398601409006",
         "-0.5891811925299969",
         "-0.8445354759225877"
        ],
        [
         "6",
         "1.32425e+18",
         "2020-11-05 07:04:22",
         "California 🔥",
         "This is crazy!!! Thank you for your loving support & checking up on us after our devastating house fire. You always stopped by so happy & always made us laugh too. #ripfrank http",
         null,
         "POINT (-118.41190649999999 34.02069278261392)",
         null,
         "This is crazy!!! Thank you for your loving support & checking up on us after our devastating house fire. You always stopped by so happy & always made us laugh too. #ripfrank https://t.co/T2aTKpeIat",
         "1",
         "-13181553.14",
         "4031673.022",
         null,
         null,
         "Related but not relevant",
         "Not related",
         null,
         "84951.32051535742",
         "Not related",
         "Not related",
         "Not related",
         "0.0",
         "-16.927222222222223",
         "16.927222222222223",
         "23.0",
         "25.0",
         "27.0",
         "53.0",
         "174.0",
         "[0.01085282 0.93662351 0.03059121 0.02193252]",
         "[0.45474356 0.39243612 0.15282033]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "-0.7146476346465247",
         "-0.3700000949320895",
         "0.7985912484346517",
         "0.612822298618291",
         "-0.08301877566464443",
         "-0.5539059556027954"
        ],
        [
         "7",
         "1.41562e+18",
         "2021-07-15 10:30:59",
         "Germany 🌊",
         "Meine Geburtsstadt hat es wieder richtig erwischt, zumal die Talsperren jetzt in die Wupper abgeleitet werden #Hochwasserhttp",
         "de",
         "POINT (7.1117483474252685 50.70022016218676)",
         null,
         "Meine Geburtsstadt hat es wieder richtig erwischt, zumal die Talsperren jetzt in die Wupper abgeleitet werden #Hochwasser\r\n\r\nhttps://t.co/ypNwhPDLnd",
         "1",
         "792214.7854",
         "6569017.368",
         "My hometown has been hit hard again, especially since the dams are now being diverted into the Wupper #Floodhttp",
         "2 - eher relevant",
         "Related and relevant",
         "Related and relevant",
         null,
         "24938.085005021654",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "0.0",
         "0.0",
         "9.0",
         "28.0",
         "61.0",
         "271.0",
         "735.0",
         "[0.1417273  0.80946314 0.01991245 0.02889714]",
         "[0.20056871 0.21911845 0.58031285]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "2",
         "True",
         "-0.7504489212807045",
         "-0.18011770725511178",
         "-0.06943279021301829",
         "1.2119118497833807",
         "0.9438166053767911",
         "-0.3044357060918154"
        ],
        [
         "8",
         "1.41603e+18",
         "2021-07-16 13:36:53",
         "Germany 🌊",
         "#Unwetter #Unwetterkatastrophe#NRW #RheinlandPfalz#Unwetterlagehttp",
         "und",
         "POINT (7.005590582384949 50.612091300974406)",
         null,
         "#Unwetter #Unwetterkatastrophe\r\n#NRW #RheinlandPfalz\r\n#Unwetterlage\r\n\r\nhttps://t.co/q7ox6AmGiw",
         "1",
         "780397.4422",
         "6553535.553",
         "#storm #stormcatastrophe#NRW #RhinelandPalatinate#stormsituationhttp",
         null,
         "Not related",
         "Related and relevant",
         null,
         "17934.497524542734",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "0.0",
         "0.0",
         "28.0",
         "41.0",
         "62.0",
         "350.0",
         "1216.0",
         "[0.11422838 0.34568387 0.31948549 0.22060223]",
         "[0.16629706 0.78405315 0.0496498 ]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "2",
         "True",
         "-0.7504489212807045",
         "-0.18011770725511178",
         "0.6149248147455673",
         "1.2409089351238227",
         "1.4103095608517047",
         "0.2761127456603184"
        ],
        [
         "9",
         "1.41499e+18",
         "2021-07-13 16:33:25",
         "Germany 🌊",
         "+++Es hat aufgehört wenig zu regnen. +++#Koblenz #twetter",
         "de",
         "POINT (7.6063659577442335 50.34845101890018)",
         null,
         "+++Es hat aufgehört wenig zu regnen. +++#Koblenz #twetter",
         "0",
         "847266.2254",
         "6507406.603",
         "+++It has stopped raining a little. +++#Koblenz #tweather",
         null,
         "Not related",
         "Related and relevant",
         null,
         "0.0",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "3.5058796770822824",
         "-7.4430555555555555",
         "7.4430555555555555",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.22894397 0.39319205 0.15076843 0.22709554]",
         "[0.23472574 0.68932331 0.07595098]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "2",
         "True",
         "-0.727258391022246",
         "-0.21410193714032877",
         "-0.3936021820355061",
         "-0.556910355983574",
         "-0.6564313811257602",
         "-1.1915523631350968"
        ],
        [
         "10",
         "1.27664e+18",
         "2020-06-26 22:01:14",
         "California 🔥",
         "Did Derek Chauvin expect this shit storm?  He had to expect something but America on fire probably wasn’t one of them!",
         null,
         "POINT (-117.29409599999997 34.13488874675305)",
         null,
         "Did Derek Chauvin expect this shit storm?  He had to expect something but America on fire probably wasn’t one of them!",
         "1",
         "-13057119.04",
         "4046939.274",
         null,
         null,
         "Not related",
         "Not related",
         null,
         "22759.415549655445",
         "Not related",
         "Not related",
         "Not related",
         "0.0",
         "166.02055555555555",
         "166.02055555555555",
         "2.0",
         "2.0",
         "3.0",
         "9.0",
         "154.0",
         "[0.00175583 0.00133089 0.98813814 0.0087752 ]",
         "[0.04727239 0.20007473 0.75265282]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "-0.7146476346465247",
         "2.557641998663736",
         "-0.3178339751295102",
         "-0.4087518621890694",
         "-0.6441658987900176",
         "-0.6099684969335707"
        ],
        [
         "11",
         "1.33715e+18",
         "2020-12-10 21:31:56",
         "California 🔥",
         "that tapatio ramen is fireeeee lol",
         null,
         "POINT (-117.97515400000002 34.09399934853786)",
         null,
         "that tapatio ramen is fireeeee lol",
         "0",
         "-13132934.07",
         "4041432.279",
         null,
         null,
         "Not related",
         "Not related",
         null,
         "10538.882773989812",
         "Not related",
         "Not related",
         "Not related",
         "3.592673984196445",
         "-50.467777777777776",
         "50.467777777777776",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.00995803 0.00573887 0.97499555 0.00930756]",
         "[0.03584657 0.85166341 0.11249001]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "-0.30602632244647937",
         "-0.9067365531705084",
         "-0.4241601868975256",
         "-0.5364486322899894",
         "-0.7589459921565712",
         "-1.0416500651805396"
        ],
        [
         "12",
         "1.6227e+18",
         "2023-02-06 20:56:29",
         "Turkey 🪨",
         "Bu son depremi hisseden bölge olarak Çukurova Bölgesi' nde bulunan yurttaşlarımız da lütfen #depremcantası deprem çantalarınızı hazırlayıp acil durumda çıkış yapabileceğiniz bir yerde bulundurunuz. İlk açık alana çıkışınızda hayat kurtarıcı olacaktır.",
         "tr",
         "POINT (34.89645910213033 36.915803652001294)",
         null,
         "Bu son depremi hisseden bölge olarak Çukurova Bölgesi' nde bulunan yurttaşlarımız da lütfen #depremcantası deprem çantalarınızı hazırlayıp acil durumda çıkış yapabileceğiniz bir yerde bulundurunuz. İlk açık alana çıkışınızda hayat kurtarıcı olacaktır.",
         "1",
         "3884774.151",
         "4427953.73",
         "Our citizens in the Çukurova Region, which felt this latest earthquake, please prepare your #earthquakebag earthquake bags and keep them somewhere you can exit in case of emergency. It will be a lifesaver when you first go out into the open.",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "8010.652940651402",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "110.98982424644136",
         "-69.88543472222223",
         "69.88543472222223",
         "10.0",
         "11.0",
         "11.0",
         "135.0",
         "1505.0",
         null,
         null,
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "1",
         "True",
         "-0.6077948499953739",
         "-0.5685301075048111",
         "-0.166771195956925",
         "-0.3228497085993613",
         "0.9136330320312324",
         "0.1656790977452674"
        ],
        [
         "13",
         "1.41208e+18",
         "2021-07-05 15:57:01",
         "Germany 🌊",
         "@user Kurze Frage: Sind in dem Modell Kapazitäten für die Influenza ab 4Q21 berücksichtigt?Kann gegen Influenza und SARS-COV-2 gleichzeitig geimpft werdenIst der Rückgang der täglichen Impfkapazität mit den für Influenza in 4Q21 benötigten begründet?",
         "de",
         "POINT (6.946579166066256 50.611418334660485)",
         null,
         "@rki_de Kurze Frage: Sind in dem Modell Kapazitäten für die Influenza ab 4Q21 berücksichtigt?\r\nKann gegen Influenza und SARS-COV-2 gleichzeitig geimpft werden\r\nIst der Rückgang der täglichen Impfkapazität mit den für Influenza in 4Q21 benötigten begründet?",
         "0",
         "773828.9243",
         "6553420.612",
         "@user Quick question: Does the model take into account capacities for influenza from 4Q21?Can vaccinations be carried out against influenza and SARS-COV-2 at the same time?Is the decline in daily vaccination capacity due to the capacity needed for influenza in 4Q21?",
         null,
         "Not related",
         "Not related",
         null,
         "20589.639459147118",
         "Not related",
         "Not related",
         "Not related",
         "0.0",
         "-200.04972222222221",
         "200.04972222222221",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.69185805 0.11656633 0.027826   0.16374962]",
         "[0.68336463 0.28495038 0.03168501]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "0",
         "True",
         "-0.7504489212807045",
         "-1.0935242642435685",
         "-0.3936021820355061",
         "-0.556910355983574",
         "-0.6564313811257602",
         "-1.1915523631350968"
        ],
        [
         "14",
         "1.62403e+18",
         "2023-02-10 12:52:45",
         "Chile 🔥",
         "Alcalde: Hay gente que se interna en el bosque, prende fuego y es recogida en vehículos sin patente http vía @user",
         "es",
         "POINT (-70.65701531594131 -33.45079580029234)",
         null,
         "Alcalde: Hay gente que se interna en el bosque, prende fuego y es recogida en vehículos sin patente https://t.co/qevfUIVDAP vía @Cooperativa",
         "1",
         "-7865792.417",
         "-3955475.786",
         "Mayor: There are people who go into the forest, set fires and are picked up in vehicles without license plates http via @user",
         null,
         "Related and relevant",
         "Related but not relevant",
         null,
         "0.0",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "11.643880201191955",
         "84.87916666666666",
         "84.87916666666666",
         "100.0",
         "253.0",
         "318.0",
         "583.0",
         "2036.0",
         "[0.10547355 0.78653771 0.00251894 0.10546976]",
         "[0.85564637 0.13092873 0.01342501]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "1",
         "True",
         "-0.28430173054708957",
         "0.9228624241802957",
         "6.569317077326143",
         "4.2093084367862605",
         "3.4814098515863283",
         "1.949485866768233"
        ],
        [
         "15",
         "1.62938e+18",
         "2023-02-25 07:13:35",
         "Turkey 🪨",
         "Kaybettiğimiz,yitirdiğimiz kim varsa Daha güzel bir dünyada tekrar buluşacağımızı biliyorum #günaydın#rojbaş http",
         "tr",
         "POINT (34.579696523337375 36.78701361392432)",
         "http://pbs.twimg.com/media/Fpy3nhjWwAA5X8p.jpg",
         "Kaybettiğimiz,yitirdiğimiz kim varsa \r\nDaha güzel bir dünyada tekrar buluşacağımızı biliyorum \r\n\r\n#günaydın\r\n#rojbaş https://t.co/xM3OWTV3Lc",
         "0",
         "3849515.489",
         "4410037.569",
         "Whoever we lost, whom we lost, I know we will meet again in a more beautiful world #goodmorning#rojbaş http",
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "8010.5122738443315",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "125.78000714074548",
         "372.3995652777778",
         "372.3995652777778",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.02629573 0.7017858  0.00361506 0.26830333]",
         "[0.90184909 0.07596409 0.02218679]",
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "1",
         "True",
         "-0.5330154742457646",
         "0.5926371044920888",
         "-0.5444014556251433",
         "-0.6356486669689778",
         "-0.6469817396285057",
         "-1.1098015510551704"
        ],
        [
         "16",
         "1.62225e+18",
         "2023-02-05 15:01:58",
         "Chile 🔥",
         "Cabrero región del bio bio. El cielo ahora.Mi hermano mayor me mando esta foto la mañana de hoy. Mucho humo y cenizas me dice mi hermano por los incendios forestales 🥺Hace mucha calor.@user @user @user@user@user@user http",
         "es",
         "POINT (-72.93807499617668 -36.84604599822322)",
         "http://pbs.twimg.com/media/FoNjByqX0AE4oRh.jpg",
         "Cabrero región del bio bio. El cielo ahora.\r\n\r\nMi hermano mayor me mando esta foto la mañana de hoy. Mucho humo y cenizas me dice mi hermano por los incendios forestales 🥺\r\n\r\nHace mucha calor.\r\n\r\n@NestorAburto2 @JorgeElgueta14 @Tragahumosfire\r\n@RafaVenegas\r\n@mariacecilia388\r\n@_unica70_ https://t.co/b5axlhqQrf",
         "1",
         "-8122816.375",
         "-4417132.25",
         "Cabrero region of Bio Bio. The sky now. My older brother sent me this photo this morning. Lots of smoke and ashes my brother tells me because of the forest fires 🥺It's very hot.@user @user @user@user@user@user http",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "0.0",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "6.572632572484517",
         "-128.96722222222223",
         "128.96722222222223",
         "0.0",
         "120.0",
         "124.0",
         "241.0",
         "1381.0",
         "[0.00143672 0.00111876 0.99641478 0.00102976]",
         "[0.03594213 0.3012253  0.66283256]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "2",
         "True",
         "-0.3549749036680098",
         "-1.3454667772216666",
         "-0.4803320234785575",
         "1.3184748529398171",
         "1.045487163791205",
         "0.9488764883315018"
        ],
        [
         "17",
         "1.62437e+18",
         "2023-02-11 11:41:21",
         "Turkey 🪨",
         "Hatay’da yaralıların büyük kısmı çevre illere sevk edildi.Ama hala sokakta kalan insanlar var. Geceleri hava aşırı soğuk.Çadır,battaniye,gıda,kan vb şeyleri bağışlamayı unutmayın!!! BURDA EN BÜYÜK SIKINTI BARINMA…",
         "tr",
         "POINT (36.162347531174625 36.20291387461083)",
         null,
         "Hatay’da yaralıların büyük kısmı çevre illere sevk edildi.Ama hala sokakta kalan insanlar var. Geceleri hava aşırı soğuk.Çadır,battaniye,gıda,kan vb şeyleri bağışlamayı unutmayın!!! \r\nBURDA EN BÜYÜK SIKINTI BARINMA…",
         "1",
         "4025676.691",
         "4329217.143",
         "Most of the injured in Hatay were sent to neighboring provinces. But there are still people left on the streets. The weather is extremely cold at night. Don't forget to donate tents, blankets, food, blood, etc.!!! THE BIGGEST PROBLEM HERE IS SHELTER...",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "60916.83894086536",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "63.88590694444445",
         "63.88590694444445",
         "38.0",
         "94.0",
         "97.0",
         "181.0",
         "3546.0",
         null,
         null,
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "2",
         "True",
         "-1.1689609850608218",
         "-0.21732919440993323",
         "0.8905935311140865",
         "2.1226694204721865",
         "1.4453980653375134",
         "1.895417306517157"
        ],
        [
         "18",
         "1.41568e+18",
         "2021-07-15 14:46:34",
         "Germany 🌊",
         "Das ist klass. 🛳#Hochwasser",
         "de",
         "POINT (13.420310237508296 52.50347058035957)",
         null,
         "Das ist klass. 🛳#Hochwasser",
         "1",
         "1494420.36",
         "6892326.333",
         "That's great. 🛳#Flood",
         "3 - wenig relevant",
         "Not related",
         "Related but not relevant",
         null,
         "61678.99303910136",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "385.69533504901614",
         "0.0",
         "0.0",
         "42.0",
         "42.0",
         "44.0",
         "47.0",
         "835.0",
         "[0.13426036 0.15372112 0.07583386 0.63618463]",
         "[0.68429381 0.29288825 0.02281794]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "1.800830689502867",
         "-0.18011770725511178",
         "1.1191883131361038",
         "0.7189613989958688",
         "-0.3788975974887863",
         "-0.18373956227640295"
        ],
        [
         "19",
         "1.62249e+18",
         "2023-02-06 06:41:30",
         "Turkey 🪨",
         "Hatay  İskenderun Gürsel konarlı MahallesiAsrı caddesi sunar apartmanı  Adresi bukadar biliyorum oralarda olan var mı varsa bana bir şekilde ulaşabilir mi lütfen @user #iskenderun#DEPREMOLDU  #deprem",
         "tr",
         "POINT (35.28385588865084 36.99870957762978)",
         null,
         "Hatay  İskenderun Gürsel konarlı Mahallesi\r\nAsrı caddesi sunar apartmanı  \r\n\r\nAdresi bukadar biliyorum oralarda olan var mı varsa bana bir şekilde ulaşabilir mi lütfen @AFADBaskanlik #iskenderun\r\n#DEPREMOLDU  #deprem",
         "1",
         "3927894.874",
         "4439504.42",
         "Hatay Iskenderun Gursel Konarli Neighborhood Asri Street Sunar Apartment I know the address this much. Is there anyone there, if so can they contact me in some way please @user #iskenderun#EARTHQUAKE #earthquake",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "17586.435330240987",
         "Related but not relevant",
         "Related but not relevant",
         "Related and relevant",
         "85.6475889773792",
         "-0.712183888888889",
         "0.712183888888889",
         "37.0",
         "38.0",
         "45.0",
         "55.0",
         "757.0",
         null,
         null,
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "2",
         "True",
         "-0.7359255531153481",
         "-0.386923878908083",
         "0.8528305051472646",
         "0.6439834354521808",
         "-0.011175721544908696",
         "-0.4682474971402658"
        ],
        [
         "20",
         "1.61587e+18",
         "2023-01-19 00:15:18",
         "Chile 🔥",
         "@user aun sin internet en Talcahuano, tampoco responden los DM, ni teléfono. Necesito saber hora de reposición del servicio @user @user @user",
         "es",
         "POINT (-73.0561405008153 -36.7016453209488)",
         null,
         "@AyudaMovistarCL aun sin internet en Talcahuano, tampoco responden los DM, ni teléfono. Necesito saber hora de reposición del servicio @SERNAC @subtel_chile @ReclamosSubtel",
         "1",
         "-8135970.443",
         "-4397033.214",
         "@user still without internet in Talcahuano, they don't answer DMs or phone calls either. I need to know when the service will be restored @user @user @user",
         null,
         "Not related",
         "Not related",
         null,
         "0.0",
         "Not related",
         "Not related",
         "Not related",
         "6.055237342112598",
         "-47.745",
         "47.745",
         "0.0",
         "2.0",
         "2.0",
         "34.0",
         "439.0",
         "[0.01353492 0.00159387 0.85732126 0.12755004]",
         "[0.14197066 0.54856342 0.30946589]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "0",
         "True",
         "-0.3621853507542494",
         "-0.48391966657509167",
         "-0.4803320234785575",
         "-0.4994720399945445",
         "-0.42888709461110636",
         "-0.49016783913017886"
        ],
        [
         "21",
         "1.25203e+18",
         "2020-04-20 00:25:22",
         "California 🔥",
         "Authorities confirm 64-year-old Rosie Hixson died Saturday in an East Central Fresno fire that broke out in her apartment. It was hard for her to escape since she suffered from mobility issues. Her daughter has now lost nearly everyone. Hear from her tonight at 6 on @user http",
         null,
         "POINT (-119.78250405154994 36.779314245027294)",
         null,
         "Authorities confirm 64-year-old Rosie Hixson died Saturday in an East Central Fresno fire that broke out in her apartment. It was hard for her to escape since she suffered from mobility issues. Her daughter has now lost nearly everyone. Hear from her tonight at 6 on @ABC30 https://t.co/w2jDcsiVAK",
         "1",
         "-13334122.95",
         "4409342.671",
         null,
         null,
         "Related and relevant",
         "Not related",
         null,
         "38123.323806903325",
         "Not related",
         "Not related",
         "Not related",
         "7.360609304051053",
         "-143.57722222222222",
         "143.57722222222222",
         "3.0",
         "3.0",
         "3.0",
         "4.0",
         "108.0",
         "[7.16335664e-04 5.34375431e-04 9.95387733e-01 3.36164003e-03]",
         "[0.0251485  0.0858361  0.88901538]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "0.12252875420578062",
         "-2.396730759047047",
         "-0.2646708692455025",
         "-0.4087518621890694",
         "-0.7079326173269918",
         "-0.7389123419943536"
        ],
        [
         "22",
         "1.41557e+18",
         "2021-07-15 07:08:54",
         "Germany 🌊",
         "Bärebach zwischen Biberist und Lüsslingen SO führt sehr viel Wasser. #Hochwasser http",
         "de",
         "POINT (7.540049890479788 47.17764138544584)",
         "http://pbs.twimg.com/ext_tw_video_thumb/1415569002882084869/pu/img/GbkgZdO5oQxVDgXp.jpg",
         "Bärebach zwischen Biberist und Lüsslingen SO führt sehr viel Wasser. #Hochwasser https://t.co/17wIgSC5uz",
         "1",
         "839852.0134",
         "5971706.998",
         "Bärebach between Biberist and Lüsslingen SO carries a lot of water. #Flood http",
         "1 - sehr relevant",
         "Related and relevant",
         "Related and relevant",
         null,
         "6829.866342914291",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "281.7348719508146",
         "0.0",
         "0.0",
         "1.0",
         "2.0",
         "2.0",
         "18.0",
         "660.0",
         "[0.88400686 0.01759739 0.01688425 0.08151145]",
         "[0.65988332 0.29109687 0.04901974]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "1.1131578406820422",
         "-0.18011770725511178",
         "-0.3575833607218964",
         "-0.4989161853026902",
         "-0.5501418469669191",
         "-0.3949578139533747"
        ],
        [
         "23",
         "1.41546e+18",
         "2021-07-15 00:08:06",
         "Germany 🌊",
         "@user @user @user @user Bloß nicht. In den Hochwassergebieten haben die Leute auch so genug am Hals.",
         "de",
         "POINT (6.241255158581256 51.66316679952648)",
         null,
         "@RoNe38775986 @ladybundlebrent @jawl @ArminLaschet Bloß nicht. In den Hochwassergebieten haben die Leute auch so genug am Hals.",
         "1",
         "700882.3195",
         "6741676.246",
         "@user @user @user @user No way. People in the flood areas have enough to deal with as it is.",
         "3 - wenig relevant",
         "Related but not relevant",
         "Related but not relevant",
         null,
         "14149.8858187031",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "29.74180250400456",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "4.0",
         "598.0",
         "[0.66394436 0.03712915 0.04602556 0.25290096]",
         "[0.66433853 0.28578508 0.04987643]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "-0.5537142257294206",
         "-0.18011770725511178",
         "-0.3936021820355061",
         "-0.5279132706431321",
         "-0.6328114846460178",
         "-0.46978942311893046"
        ],
        [
         "24",
         "1.30659e+18",
         "2020-09-17 13:27:24",
         "California 🔥",
         "@user Still thinking about how CA has been defunding firefighters and expecting them to fight with extremely outdated equipment while police funds skyrocket and yearly fire damage continues to rise",
         null,
         "POINT (-117.92489449999997 34.09949513837219)",
         null,
         "@PriusGod Still thinking about how CA has been defunding firefighters and expecting them to fight with extremely outdated equipment while police funds skyrocket and yearly fire damage continues to rise",
         "1",
         "-13127339.21",
         "4042169.92",
         null,
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "3983.7945089419372",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "5.186374884318003",
         "0.0",
         "0.0",
         "1.0",
         "5.0",
         "26.0",
         "302.0",
         "747.0",
         "[0.00892898 0.42832634 0.26067615 0.3020685 ]",
         "[0.24764621 0.30169395 0.45065987]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "1",
         "True",
         "-0.12476296375413214",
         "-0.09912034494341272",
         "-0.3709970810135179",
         "0.5702567085846509",
         "3.092563807476672",
         "1.052285853523914"
        ],
        [
         "25",
         "1.31114e+18",
         "2020-09-30 02:51:36",
         "California 🔥",
         "@user My father was a CAL fire firefighter for 15+ years. I have friends that are employed as well by the state as firefighters. Every one of them blame California and the bills passed that make management more difficult.",
         null,
         "POINT (-117.656773 33.60351023417285)",
         null,
         "@joshfoxfilm My father was a CAL fire firefighter for 15+ years. I have friends that are employed as well by the state as firefighters. Every one of them blame California and the bills passed that make management more difficult.",
         "1",
         "-13097492.06",
         "3975689.925",
         null,
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "18328.64166031638",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "15.0",
         "346.0",
         "[0.00615004 0.02571008 0.01809332 0.95004654]",
         "[0.37843338 0.45998275 0.16158384]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "1",
         "True",
         "-0.7146476346465247",
         "-0.09912034494341272",
         "-0.3709970810135179",
         "-0.4938830422563494",
         "-0.5676458365456485",
         "-0.07176810015812878"
        ],
        [
         "26",
         "1.45189e+18",
         "2021-10-23 12:36:49",
         "Germany 🌊",
         "#nowplaying #EdSheeran ~ Ed Sheeran | Bad Habits ||| #bbradio #rocks #berlin",
         "en",
         "POINT (13.115676182460431 52.37913567174468)",
         null,
         "#nowplaying #EdSheeran ~ Ed Sheeran | Bad Habits ||| #bbradio #rocks #berlin",
         "0",
         "1460510.984",
         "6869475.542",
         "#nowplaying #EdSheeran ~ Ed Sheeran | Bad Habits ||| #bbradio #rocks #berlin",
         "4 - nicht relevant",
         "Not related",
         "Not related",
         null,
         "0.0",
         "Not related",
         "Not related",
         "Not related",
         "388.8693148054896",
         "2364.613611111111",
         "2364.613611111111",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.86696064 0.05144973 0.01250745 0.0690821 ]",
         "[0.95056814 0.03313532 0.01629656]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "0",
         "True",
         "1.8218257835625387",
         "10.616466027731537",
         "-0.3936021820355061",
         "-0.556910355983574",
         "-0.6564313811257602",
         "-1.1915523631350968"
        ],
        [
         "27",
         "1.62226e+18",
         "2023-02-05 15:48:16",
         "Chile 🔥",
         "12:48 en Huechuraba 2da. Alarma de Incendio B-1 R-1 B-2 Q-2 B-3 Q-5 R-6 B-7 B-8 Las Petunias y Los Retamos http",
         "es",
         "POINT (-70.62020265490838 -33.37543349841226)",
         null,
         "12:48 en Huechuraba 2da. Alarma de Incendio B-1 R-1 B-2 Q-2 B-3 Q-5 R-6 B-7 B-8 Las Petunias y Los Retamos https://t.co/cTgY4av7E9",
         "1",
         "-7861694.134",
         "-3945425.328",
         "12:48 in Huechuraba 2nd Fire Alarm B-1 R-1 B-2 Q-2 B-3 Q-5 R-6 B-7 B-8 Las Petunias and Los Retamos http",
         null,
         "Related and relevant",
         "Not related",
         null,
         "0.0",
         "Not related",
         "Not related",
         "Not related",
         "12.51627366580892",
         "-32.19555555555556",
         "32.19555555555556",
         "1.0",
         "47.0",
         "211.0",
         "422.0",
         "1396.0",
         "[0.00172749 0.01017802 0.00312355 0.98497099]",
         "[0.82809705 0.14263625 0.02926669]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "0",
         "True",
         "-0.27214400943613115",
         "-0.3189823062475473",
         "-0.4098355324705105",
         "2.614879604458583",
         "2.3346743172734197",
         "0.971791206921656"
        ],
        [
         "28",
         "1.2962e+18",
         "2020-08-19 21:50:16",
         "California 🔥",
         "I live in California.  There are fires everywhere and I can't breath. Should I move to Idaho, Texas, Florida, Georgia or Utah?",
         null,
         "POINT (-120.846039 35.37807161161749)",
         null,
         "I live in California.  There are fires everywhere and I can't breath. Should I move to Idaho, Texas, Florida, Georgia or Utah?",
         "1",
         "-13452519.53",
         "4215380.298",
         null,
         null,
         "Related but not relevant",
         "Related and relevant",
         null,
         "10177.615021105856",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "45.83777777777778",
         "45.83777777777778",
         "1.0",
         "1.0",
         "3.0",
         "9.0",
         "601.0",
         "[0.58444482 0.02615663 0.30444986 0.0849487 ]",
         "[0.89921612 0.06650717 0.03427675]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "2",
         "True",
         "-0.7146476346465247",
         "0.6344037750495555",
         "-0.3709970810135179",
         "-0.4087518621890694",
         "-0.6441658987900176",
         "0.643029301809255"
        ],
        [
         "29",
         "1.66207e+18",
         "2023-05-26 12:28:19",
         "Italy 🌊",
         "@user @user Ed è esattamente quello che hanno intenzione di fare. Morrone, deputato leghista di Forlì dove venne a studiare, stamattina ha detto ad Agorà che l’Emilia  Romagna è allo sfascio e che loro (lega) la rimetteranno in sesto",
         "it",
         "POINT (12.062749626989211 44.22474512490816)",
         null,
         "@vincenzolambia4 @Antigon25386936 Ed è esattamente quello che hanno intenzione di fare. Morrone, deputato leghista di Forlì dove venne a studiare, stamattina ha detto ad Agorà che l’Emilia  Romagna è allo sfascio e che loro (lega) la rimetteranno in sesto",
         "0",
         "1343238.929",
         "5500892.567",
         "@user @user And that's exactly what they intend to do. Morrone, a member of the Northern League from Forlì where he came to study, told Agorà this morning that Emilia Romagna is in shambles and that they (the Northern League) will fix it up",
         null,
         "Related but not relevant",
         "Not related",
         null,
         "31866.899152134545",
         "Not related",
         "Not related",
         "Not related",
         "0.0",
         "228.47194444444443",
         "228.47194444444443",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.01728764 0.48810321 0.06259726 0.43201184]",
         "[0.63246346 0.34010974 0.02742678]",
         "[0 0 0 1 0]",
         "[1 0 0]",
         "11.266238694068402",
         "44.438038246664384",
         "0.24008244558466105",
         "-0.8652443925342407",
         "0.4401278910841043",
         "0",
         "True",
         "-0.675560130808516",
         "1.5150910651836536",
         "-0.5799732311736391",
         "-0.6295734294711209",
         "-0.9414235672391693",
         "-1.0883545314597871"
        ],
        [
         "30",
         "1.29738e+18",
         "2020-08-23 03:41:01",
         "California 🔥",
         "Oh.....those beautiful trees.  😟California’s Iconic Giant Redwood Trees Burn Amidst Massive Wildfire – Deadline http",
         null,
         "POINT (-117.59572749999998 33.629409844692084)",
         null,
         "Oh.....those beautiful trees.  😟California’s Iconic Giant Redwood Trees Burn Amidst Massive Wildfire – Deadline https://t.co/S5wGGY32wU",
         "1",
         "-13090696.5",
         "3979150.737",
         null,
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "11641.903929234482",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "0.4058765051793693",
         "27.683611111111112",
         "27.683611111111112",
         "1.0",
         "1.0",
         "1.0",
         "19.0",
         "1020.0",
         "[0.97335148 0.01461275 0.00241038 0.00962531]",
         "[0.94138896 0.04737684 0.01123416]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "1",
         "True",
         "-0.6684843059205933",
         "0.3438897105822284",
         "-0.3709970810135179",
         "-0.4938830422563494",
         "-0.5166324617160691",
         "1.817539542688995"
        ],
        [
         "31",
         "1.30282e+18",
         "2020-09-07 03:56:42",
         "California 🔥",
         "😢💔  This painting is a quick, heartfelt expression of loss. Based on photos that I believe were taken by firefighters near Huntington Lake, CA.9x10 in. Acrylic@user #artist#forests#wildfires#huntingtonLake#CreekFire#california #prayForRain http",
         null,
         "POINT (-119.02516299999998 35.34682273861133)",
         null,
         "😢💔  \r\nThis painting is a quick, heartfelt expression of loss. Based on photos that I believe were taken by firefighters near Huntington Lake, CA.\r\n9x10 in. Acrylic\r\n@dailypaintworks \r\n#artist\r\n#forests\r\n#wildfires\r\n#huntingtonLake\r\n#CreekFire\r\n#california \r\n#prayForRain https://t.co/Yqg5OjZP6L",
         "1",
         "-13249820.54",
         "4211131.182",
         null,
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "24860.824637372978",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "0.0",
         "-44.055",
         "44.055",
         "2.0",
         "2.0",
         "2.0",
         "2.0",
         "345.0",
         "[0.97344923 0.00240877 0.00404379 0.0200983 ]",
         "[0.93163818 0.05496901 0.0133928 ]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "1",
         "True",
         "-0.7146476346465247",
         "-0.8041153659271038",
         "-0.3178339751295102",
         "-0.4513174522227094",
         "-0.7334393047417814",
         "-0.07457122722466754"
        ],
        [
         "32",
         "1.63347e+18",
         "2023-03-08 13:58:00",
         "Turkey 🪨",
         "Deprem bölgesinde dinamit patlatıyınca  buyuk korku yaşandı http",
         "tr",
         "POINT (36.17472442239599 36.56689410957244)",
         "http://pbs.twimg.com/media/Fqs9q2nakAMqhzO.jpg",
         "Deprem bölgesinde dinamit patlatıyınca  buyuk korku yaşandı https://t.co/fD3dDzuWn6",
         "1",
         "4027055.104",
         "4379482.446",
         "There was great fear when dynamite was detonated in the earthquake area http",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "6586.977158237249",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "11.397709924228048",
         "726.7973286111111",
         "726.7973286111111",
         "5.0",
         "6.0",
         "6.0",
         "47.0",
         "694.0",
         "[0.00316388 0.96953088 0.01172528 0.01557991]",
         "[0.53708142 0.29822075 0.16469781]",
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "2",
         "True",
         "-1.1113340010539412",
         "1.5230667206619877",
         "-0.35558632579103416",
         "-0.46503105331282335",
         "-0.10365659690252281",
         "-0.5216397103458655"
        ],
        [
         "33",
         "1.41753e+18",
         "2021-07-20 17:15:24",
         "Germany 🌊",
         "Heute Abend BM Andreas Geron aus Sinzig bei Markus Lanz: Die HochwasserkatastropheIm ZDF: 20.07.2021, 22:45 - 00:15Mediathek ab: 21.07.2021, 01:00http#Flutkatastrophe #fluthilfe #Flut #Sinzig #BadBodendorf #Franken #Koisdorf #Westum #Lanz #ZDF http",
         "de",
         "POINT (7.2129873574971555 50.52491673116137)",
         "http://pbs.twimg.com/media/E6wXTnQXsAAbzyp.jpg",
         "Heute Abend BM Andreas Geron aus Sinzig bei Markus Lanz: Die Hochwasserkatastrophe\r\nIm ZDF: 20.07.2021, 22:45 - 00:15\r\nMediathek ab: 21.07.2021, 01:00\r\nhttps://t.co/1Td18uVCc3\r\n\r\n#Flutkatastrophe #fluthilfe #Flut #Sinzig #BadBodendorf #Franken #Koisdorf #Westum #Lanz #ZDF https://t.co/vzA3bOnGKo",
         "1",
         "803481.598",
         "6538255.648",
         "Tonight BM Andreas Geron from Sinzig with Markus Lanz: The flood disasterOn ZDF: 20.07.2021, 22:45 - 00:15Media library from: 21.07.2021, 01:00http#flooddisaster #floodaid #flood #Sinzig #BadBodendorf #Franken #Koisdorf #Westum #Lanz #ZDF http",
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "13115.661061441526",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "0.0",
         "89.25666666666666",
         "89.25666666666666",
         "15.0",
         "19.0",
         "122.0",
         "620.0",
         "2492.0",
         "[0.07898453 0.5450173  0.24323122 0.1327669 ]",
         "[0.77405548 0.20767137 0.01827313]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "-0.7504489212807045",
         "0.22741909750836908",
         "0.14668013766864027",
         "2.9807340555503354",
         "3.0046525732343206",
         "1.8161955407449812"
        ],
        [
         "34",
         "1.29479e+18",
         "2020-08-16 00:35:40",
         "California 🔥",
         "@user @user Three continues and one in NV now have evacuation warnings of some sort due to the fire in Loyalton.",
         null,
         "POINT (-120.19266280937244 39.3409489301179)",
         null,
         "@CAFireScanner @Tahoe_NF Three continues and one in NV now have evacuation warnings of some sort due to the fire in Loyalton.",
         "1",
         "-13379900.03",
         "4770603.22",
         null,
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "9522.16644681245",
         "Related but not relevant",
         "Related and relevant",
         "Related and relevant",
         "27.035302735439583",
         "0.0",
         "0.0",
         "2.0",
         "3.0",
         "3.0",
         "4.0",
         "238.0",
         "[0.13375422 0.54085827 0.01041619 0.31497133]",
         "[0.93865442 0.04856184 0.01278375]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "2",
         "True",
         "2.3602767609639694",
         "-0.09912034494341272",
         "-0.3178339751295102",
         "-0.4087518621890694",
         "-0.7079326173269918",
         "-0.3745058233443148"
        ],
        [
         "35",
         "1.6223e+18",
         "2023-02-05 18:40:08",
         "Chile 🔥",
         "@user le dedica el triunfo a la gente q lo esta pasando mal por estos mega incendios forestales!! 🇨🇱#VamosChile http",
         "es",
         "POINT (-72.84410970082095 -41.51154052247538)",
         "http://pbs.twimg.com/ext_tw_video_thumb/1622303908851863555/pu/img/gVHQjhh5x2d57_Fs.jpg",
         "@Garin_Cris le dedica el triunfo a la gente q lo esta pasando mal por estos mega incendios forestales!! 🇨🇱\r\n#VamosChile https://t.co/tiCa1QnoOQ",
         "1",
         "-8109320.69",
         "-5088323.681",
         "@user dedicates the victory to the people who are having a hard time because of these mega forest fires!! 🇨🇱#VamosChile http",
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "0.0",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "8.65081709773486",
         "-101.33111111111111",
         "101.33111111111111",
         "10.0",
         "10.0",
         "10.0",
         "13.0",
         "1423.0",
         "[0.28533983 0.65532911 0.03353648 0.02579459]",
         "[0.2009383  0.69194907 0.10711257]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "1",
         "True",
         "-0.32601321504944997",
         "-1.0523227210033774",
         "0.2246328866019125",
         "-0.3802624076709798",
         "-0.5784612947388771",
         "1.0130377003839335"
        ],
        [
         "36",
         "1.62301e+18",
         "2023-02-07 17:09:38",
         "Turkey 🪨",
         "@user @user @user @user @user @user @user @user @user Adıyaman'daki depremde kıbrıstan voleybol maçlarına giden 30 kişilik kafilemiz depremde enkaz altında kalmıştırHocaömer, Atatürk BV No:220/A 02100 AdıyamanVinç ve yakıt ihtiyaçları varLütfen paylaş sesimizi duyurmamız lazım arkadaşlarımız 39 saattir enkazın altında",
         "tr",
         "POINT (33.43665946749627 35.126054712265436)",
         null,
         "@geos312 @Shunjord @KendineMuzisyen @jahreindota @LEVOBALIM @buyuksehirkm @DepremDairesi @AFADBaskanlik @OguzhanUgur Adıyaman'daki depremde kıbrıstan voleybol maçlarına giden 30 kişilik kafilemiz depremde enkaz altında kalmıştır\r\nHocaömer, Atatürk BV No:220/A 02100 Adıyaman\r\nVinç ve yakıt ihtiyaçları var\r\nLütfen paylaş sesimizi duyurmamız lazım arkadaşlarımız 39 saattir enkazın altında",
         "1",
         "3722281.652",
         "4182608.134",
         "@user @user @user @user @user @user @user @user @user @user Our 30-person group that went to the Cyprus volleyball matches in the earthquake in Adıyaman was trapped under the rubble in the earthquakeHocaömer, Atatürk BV No:220/A 02100 AdıyamanThey need cranes and fuelPlease share, we need to make our voices heard, our friends have been under the rubble for 39 hours",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "156010.61043123342",
         "Related but not relevant",
         "Related but not relevant",
         "Related and relevant",
         "61.951966846236175",
         "-63.13080805555556",
         "63.13080805555556",
         "0.0",
         "56.0",
         "56.0",
         "57.0",
         "2123.0",
         null,
         null,
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "2",
         "True",
         "-0.8557309567150495",
         "-0.5507966301890234",
         "-0.5444014556251433",
         "0.9567823938217975",
         "0.011944497294494831",
         "0.6894312844287694"
        ],
        [
         "37",
         "1.62696e+18",
         "2023-02-18 14:58:56",
         "Chile 🔥",
         "11:58 en Linares Fuego en pasto y/o basura (10-2-1) B1 Camino  Llancanao y Sector La Isla http",
         "es",
         "POINT (-71.4819082137984 -35.91235504542298)",
         null,
         "11:58 en Linares Fuego en pasto y/o basura (10-2-1) B1 Camino  Llancanao y Sector La Isla https://t.co/Ly0TUL6PsJ",
         "1",
         "-7957629.272",
         "-4288753.113",
         "11:58 in Linares Fire in grass and/or garbage (10-2-1) B1 Llancanao Road and La Isla Sector http",
         null,
         "Related and relevant",
         "Related but not relevant",
         null,
         "0.0",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "1.2116174682383907",
         "14.982222222222223",
         "14.982222222222223",
         "1.0",
         "1.0",
         "8.0",
         "22.0",
         "798.0",
         "[0.75185138 0.02953788 0.14295398 0.07565674]",
         "[0.75575358 0.15597656 0.08826979]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "1",
         "True",
         "-0.42968629153664445",
         "0.18144574187904056",
         "-0.4098355324705105",
         "-0.4100648157518709",
         "-0.5143580661126896",
         "0.05825775912751048"
        ],
        [
         "38",
         "1.62596e+18",
         "2023-02-15 20:51:25",
         "Turkey 🪨",
         "Evlerimiz güvenli mi ? @user  deprem sonrası evlerde yaşamaya korkuyoruz…#kayserideprem http",
         "tr",
         "POINT (35.457405070318686 38.72521416255235)",
         "http://pbs.twimg.com/media/FpCS6DdXgBE5RF6.jpg,http://pbs.twimg.com/media/FpCS6DhWIAE29Jw.jpg",
         "Evlerimiz güvenli mi ? @csbgovtr  deprem sonrası evlerde yaşamaya korkuyoruz…\r\n#kayserideprem https://t.co/7rWrDsYUIX",
         "1",
         "3947216.431",
         "4682968.754",
         "Are our homes safe? @user We are afraid to live in our homes after the earthquake…#kayseridequake http",
         null,
         "Related and relevant",
         "Related and relevant",
         null,
         "16721.38418955449",
         "Related but not relevant",
         "Related but not relevant",
         "Related and relevant",
         "89.14144895385854",
         "160.55121805555555",
         "160.55121805555555",
         "31.0",
         "31.0",
         "38.0",
         "46.0",
         "2008.0",
         null,
         null,
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "2",
         "True",
         "-0.7182605472215882",
         "0.036454202720201896",
         "0.6262523493463336",
         "0.44492955285333396",
         "-0.11521670632222457",
         "0.5919693079423572"
        ],
        [
         "39",
         "1.63558e+18",
         "2023-03-14 09:40:59",
         "Turkey 🪨",
         "#AstsubaylaraAdaletAstsubaylar hakkı olan tazminatları için müjde bekliyor 🇹🇷🇹🇷@user@user @user@user@user @user @user @user@user  @user@user@user@user http",
         "tr",
         "POINT (32.509404594435324 37.86591141201059)",
         "http://pbs.twimg.com/media/FrK8XtYXgAUq136.jpg,http://pbs.twimg.com/media/FrK8XtaXgAEvlPQ.jpg",
         "#AstsubaylaraAdalet\r\n\r\nAstsubaylar hakkı olan tazminatları için müjde bekliyor 🇹🇷🇹🇷\r\n\r\n@RTErdogan\r\n\r\n@NureddinNebati\r\n \r\n@suleymansoylu\r\n\r\n@dbdevletbahceli\r\n\r\n@tcsavunma \r\n\r\n@kilicdarogluk \r\n\r\n@mustafaelitas \r\n\r\n@fuatoktay\r\n\r\n@_cevdetyilmaz \r\n \r\n@AhmetAYDIN_02\r\n\r\n@HMBakanligi\r\n\r\n@TSKGnkur\r\n\r\n@DurgenHamza https://t.co/sKivRiz0bQ",
         "1",
         "3619077.241",
         "4561098.719",
         "#JusticeForPetty OfficersPetty officers are waiting for good news for their rightful compensation 🇹🇷🇹🇷@user@user @user@user@user @user @user @user@user @user@user @user@user@user @user @user @user http",
         null,
         "Not related",
         "Not related",
         null,
         "37043.52224010229",
         "Not related",
         "Not related",
         "Not related",
         "326.6671374751125",
         "760.6687872222222",
         "760.6687872222222",
         "10.0",
         "10.0",
         "25.0",
         "25.0",
         "804.0",
         "[0.02132065 0.26119205 0.68602532 0.03146196]",
         "[0.06242228 0.70323014 0.2343476 ]",
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "0",
         "True",
         "0.48267272311382436",
         "1.611992248685168",
         "-0.166771195956925",
         "0.07525805659833255",
         "-0.3579790041359616",
         "-0.428415211097993"
        ],
        [
         "40",
         "1.41537e+18",
         "2021-07-14 18:10:32",
         "Germany 🌊",
         "Der Regen hat aufgehört. Der Himmel klart auf. Das Wasser zieht sich zurück.#Hagen #Starkregen #Hochwasser",
         "de",
         "POINT (7.482533160491757 51.33848070140591)",
         null,
         "Der Regen hat aufgehört. Der Himmel klart auf. Das Wasser zieht sich zurück.\r\n\r\n#Hagen #Starkregen #Hochwasser",
         "1",
         "833493.945",
         "6681964.37",
         "The rain has stopped. The sky is clearing. The water is receding. #Hagen #heavyrain #flooding",
         "1 - sehr relevant",
         "Related and relevant",
         "Related and relevant",
         null,
         "27418.831536840647",
         "Related and relevant",
         "Related and relevant",
         "Related and relevant",
         "0.0",
         "0.0",
         "0.0",
         "7.0",
         "7.0",
         "7.0",
         "21.0",
         "537.0",
         "[0.38131642 0.01601348 0.01024992 0.59242022]",
         "[0.95706189 0.02673175 0.01620637]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "2",
         "True",
         "-0.7504489212807045",
         "-0.18011770725511178",
         "-0.14147043284023783",
         "-0.3539307586004808",
         "-0.5324269246071123",
         "-0.543414070846332"
        ],
        [
         "41",
         "1.61402e+18",
         "2023-01-13 22:11:43",
         "Chile 🔥",
         "@user ,hasta que hora estaremos sin agua en glorias Navales ?..como tanto, cuando ,no es un desague, es  una tubería y si no una matriz , todos los meses pasa algo ?!..",
         "es",
         "POINT (-71.51304506358589 -33.025009401401874)",
         null,
         "@esval_chile ,hasta que hora estaremos sin agua en glorias Navales ?..como tanto, cuando ,no es un desague, es  una tubería y si no una matriz , todos los meses pasa algo ?!..",
         "1",
         "-7961085.296",
         "-3898803.003",
         "@user, until what time will we be without water in Glories Navales? .. how long, when, it is not a drain, it is a pipe and if not a matrix, does something happen every month?!..",
         null,
         "Not related",
         "Not related",
         null,
         "0.0",
         "Not related",
         "Not related",
         "Not related",
         "7.03474240698772",
         "118.19527777777778",
         "118.19527777777778",
         "15.0",
         "20.0",
         "28.0",
         "44.0",
         "461.0",
         "[0.00951454 0.00327504 0.94948483 0.03772563]",
         "[0.05082108 0.48106745 0.46811149]",
         "[0 1 0 0 0]",
         "[0 1 0]",
         "-71.06063249257306",
         "-34.92167295303011",
         "0.34207855816769434",
         "0.8695592312840196",
         "0.35615867718006844",
         "0",
         "True",
         "-0.3485349167602814",
         "1.2762558487929117",
         "0.5771153416421475",
         "-0.11204073494295923",
         "-0.35766128502645367",
         "-0.4565595851979528"
        ],
        [
         "42",
         "1.41563e+18",
         "2021-07-15 11:14:39",
         "Germany 🌊",
         "Ich sehe gerade die Bilder von #Esch Eifel. Wahnsinn wieviel Treibholz sich dort gesammelt hat. #Hochwasser",
         "de",
         "POINT (10.60683437694896 53.92814672068347)",
         null,
         "Ich sehe gerade die Bilder von #Esch Eifel. Wahnsinn wieviel Treibholz sich dort gesammelt hat. #Hochwasser",
         "1",
         "1181276.628",
         "7157073.545",
         "I'm just looking at the pictures from #Esch Eifel. It's amazing how much driftwood has collected there. #Flood",
         "3 - wenig relevant",
         "Related and relevant",
         "Related and relevant",
         null,
         "19420.937975200824",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "334.10384035849984",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "5.0",
         "756.0",
         "[0.01387076 0.00263161 0.97883213 0.0046655 ]",
         "[0.03008264 0.72736639 0.24255092]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "1.4595656636320316",
         "-0.18011770725511178",
         "-0.3575833607218964",
         "-0.5279132706431321",
         "-0.6269065105260822",
         "-0.2790895158905788"
        ],
        [
         "43",
         "1.65998e+18",
         "2023-05-20 18:03:59",
         "Italy 🌊",
         "Eroi ❤️ #EmiliaRomagna  #alluvioneemiliaromagna #floods #ClimateEmergency http",
         "eu",
         "POINT (12.184258334750636 44.416774092627016)",
         null,
         "Eroi ❤️ #EmiliaRomagna  #alluvioneemiliaromagna #floods #ClimateEmergency https://t.co/yMCHkDDsFn",
         "1",
         "1356765.371",
         "5530807.554",
         "Heroes ❤️ #EmiliaRomagna #floodemiliaromagna #floods #ClimateEmergency http",
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "64648.22613511048",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "0.0",
         "90.0663888888889",
         "90.0663888888889",
         "35.0",
         "35.0",
         "35.0",
         "283.0",
         "1444.0",
         "[0.03760109 0.22256176 0.00678512 0.73305207]",
         "[0.84485173 0.13502888 0.02011939]",
         "[0 0 0 1 0]",
         "[1 0 0]",
         "11.266238694068402",
         "44.438038246664384",
         "0.24008244558466105",
         "-0.8652443925342407",
         "0.4401278910841043",
         "1",
         "True",
         "-0.675560130808516",
         "0.29217995749202463",
         "0.4578736035581361",
         "0.1467298507710472",
         "0.8791869417461393",
         "1.4490786775363163"
        ],
        [
         "44",
         "1.62777e+18",
         "2023-02-20 20:20:01",
         "Turkey 🪨",
         "Tüm kanalların bangır bangır ortak yayın yapıp topladıkları paralar nereye kullanılıyor? Memleketim Hatay-Defne ve tüm ilçelerine  niçin hala yeterli yardım gitmiyor? 😡",
         "tr",
         "POINT (32.81703964654144 39.88505201447582)",
         null,
         "Tüm kanalların bangır bangır ortak yayın yapıp topladıkları paralar nereye kullanılıyor? Memleketim Hatay-Defne ve tüm ilçelerine  niçin hala yeterli yardım gitmiyor? 😡",
         "1",
         "3653325.484",
         "4849824.235",
         "Where is the money collected by all channels broadcasting together at full blast used? Why is there still not enough aid going to my hometown Hatay-Defne and all its districts? 😡",
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "14154.358690383844",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "357.5289642684494",
         "322.44153666666665",
         "322.44153666666665",
         "46.0",
         "51.0",
         "53.0",
         "153.0",
         "1096.0",
         "[8.57621490e-04 1.36829307e-02 1.00005595e-02 9.75458920e-01]",
         "[0.77923363 0.17116979 0.04959651]",
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "1",
         "True",
         "0.6387105597376753",
         "0.4614781802707716",
         "1.192697738848661",
         "0.8714735869937202",
         "1.1217150015858641",
         "-0.18094654036727684"
        ],
        [
         "45",
         "1.41828e+18",
         "2021-07-22 18:35:30",
         "Germany 🌊",
         "Cell Broadcast als Warnsystem in der #Hochwasser Katastrophe?!  Die Telekom befürwortet die Einführung eines SMS-Warnsystems in Deutschland \"Cell Broadcast, also die Warnung per SMS, muss ein Teil des Warnsystems sein\". Doch was ist #CellBroadcast? http http",
         "de",
         "POINT (7.112625787395869 50.61948166233963)",
         "http://pbs.twimg.com/media/E668z2AWEAgPHbz.jpg",
         "Cell Broadcast als Warnsystem in der #Hochwasser Katastrophe?!  Die Telekom befürwortet die Einführung eines SMS-Warnsystems in Deutschland \"Cell Broadcast, also die Warnung per SMS, muss ein Teil des Warnsystems sein\". Doch was ist #CellBroadcast? https://t.co/BmYRcZeOtI https://t.co/tfE9pf91ny",
         "1",
         "792311.522",
         "6554831.901",
         "Cell broadcast as a warning system in the #flood disaster?! Telekom supports the introduction of an SMS warning system in Germany \"Cell broadcast, i.e. warnings via SMS, must be part of the warning system\". But what is #CellBroadcast? http http",
         null,
         "Related but not relevant",
         "Related but not relevant",
         null,
         "12915.492039782926",
         "Related but not relevant",
         "Related but not relevant",
         "Related but not relevant",
         "1.0033290340771184",
         "138.59166666666667",
         "138.59166666666667",
         "6.0",
         "7.0",
         "74.0",
         "692.0",
         "2143.0",
         "[0.05948978 0.01100478 0.92282891 0.0066765 ]",
         "[0.05592492 0.74637747 0.19769754]",
         "[0 0 1 0 0]",
         "[1 0 0]",
         "8.684652155094136",
         "50.55769583882582",
         "-0.707082609359605",
         "0.6457928681909654",
         "0.2880724820854964",
         "1",
         "True",
         "-0.7438121469281633",
         "0.4526776581724427",
         "-0.1774892541538476",
         "1.5888739592091252",
         "3.4298107098696846",
         "1.3949659988291918"
        ],
        [
         "46",
         "1.65131e+18",
         "2023-04-26 19:34:35",
         "Italy 🌊",
         "@user La perversione e'proprio stata creata dalla SX, al tempo del fascismo vi erano valori della famiglia e della vita quotidiana, vi era rispetto e pudore, i fanciulli crescevano secondo natura, le leggi razziali, non possono cancellare tutto questo, che è la normalità della vita",
         "it",
         "POINT (10.764208130924759 44.54309074301842)",
         null,
         "@ilgiornale La perversione e'proprio stata creata dalla SX, al tempo del fascismo vi erano valori della famiglia e della vita quotidiana, vi era rispetto e pudore, i fanciulli crescevano secondo natura, le leggi razziali, non possono cancellare tutto questo, che è la normalità della vita",
         "0",
         "1198701.379",
         "5550464.161",
         "@user Perversion was actually created by the Left, during the Fascist era there were family values ​​and daily life, there was respect and modesty, children grew up according to nature, the racial laws cannot erase all this, which is the normality of life",
         null,
         "Not related",
         "Not related",
         null,
         "18778.942418320104",
         "Not related",
         "Not related",
         "Not related",
         "22.88161403832726",
         "-124.42361111111111",
         "124.42361111111111",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.8908062  0.01189209 0.00499318 0.09230852]",
         "[0.95184875 0.03826909 0.00988216]",
         "[0 0 0 1 0]",
         "[1 0 0]",
         "11.266238694068402",
         "44.438038246664384",
         "0.24008244558466105",
         "-0.8652443925342407",
         "0.4401278910841043",
         "0",
         "True",
         "0.2382208893427131",
         "-1.6029911029173984",
         "-0.5799732311736391",
         "-0.6295734294711209",
         "-0.9414235672391693",
         "-1.0883545314597871"
        ],
        [
         "47",
         "1.33889e+18",
         "2020-12-15 16:40:23",
         "California 🔥",
         "B41 is assuming conmand and E42 is backup fire tac. Additional PD and parking enforcement enroute to block off traffic to Cantebury",
         null,
         "POINT (-118.40898999999999 34.00600735211446)",
         null,
         "B41 is assuming conmand and E42 is backup fire tac. Additional PD and parking enforcement enroute to block off traffic to Cantebury",
         "1",
         "-13181228.47",
         "4029610.057",
         null,
         null,
         "Related and relevant",
         "Not related",
         null,
         "7823.583308418747",
         "Not related",
         "Not related",
         "Not related",
         "11.601100076158813",
         "64.67305555555555",
         "64.67305555555555",
         "1.0",
         "20.0",
         "24.0",
         "39.0",
         "111.0",
         "[0.00121249 0.0035643  0.9877243  0.00749886]",
         "[0.05206146 0.2279131  0.72002548]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "0.6048310480662721",
         "0.9358173955734026",
         "-0.3709970810135179",
         "0.4851255285173709",
         "-0.2615655875681722",
         "-0.7305029607947373"
        ],
        [
         "48",
         "1.62252e+18",
         "2023-02-06 08:45:24",
         "Turkey 🪨",
         "@user @user Merhaba, Birkent 2 sitesinde yıkım yok değil mi? Bilgi verebilirseniz sevinirim.",
         "tr",
         "POINT (30.67941573619543 36.88585402719689)",
         null,
         "@MustafaKosker @nurkosker94 Merhaba, Birkent 2 sitesinde yıkım yok değil mi? Bilgi verebilirseniz sevinirim.",
         "1",
         "3415380.941",
         "4423797.962",
         "@user @user Hello, there is no demolition at the Birkent 2 site, right? I would be glad if you could provide information.",
         null,
         "Not related",
         "Not related",
         null,
         "15815.724893430248",
         "Not related",
         "Not related",
         "Not related",
         "439.0561188401979",
         "0.5420602777777778",
         "0.5420602777777778",
         "36.0",
         "36.0",
         "37.0",
         "51.0",
         "846.0",
         "[0.00135239 0.0304569  0.0048838  0.96330696]",
         "[0.67429751 0.14560528 0.18009727]",
         "[0 0 0 0 1]",
         "[0 0 1]",
         "35.317672892549055",
         "38.79059474137815",
         "-0.3342238450701846",
         "-0.31776133384120614",
         "0.8873117581222277",
         "0",
         "True",
         "1.0509130165352256",
         "-0.38363100846895054",
         "0.8150674791804428",
         "0.41649328391064155",
         "-0.05741615922371575",
         "-0.39282040229425985"
        ],
        [
         "49",
         "1.2865e+18",
         "2020-07-24 03:29:41",
         "California 🔥",
         "Celta Vigo or #MLS 🤔 tough one..",
         null,
         "POINT (-118.13196400000001 34.17729773148105)",
         null,
         "Celta Vigo or #MLS 🤔 tough one..",
         "0",
         "-13150390.08",
         "4052638.246",
         null,
         null,
         "Not related",
         "Not related",
         null,
         "16223.553032403812",
         "Not related",
         "Not related",
         "Not related",
         "0.0",
         "-140.5052777777778",
         "140.5052777777778",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "[0.00946656 0.00836282 0.97284096 0.00932975]",
         "[0.07958552 0.37759185 0.54282266]",
         "[1 0 0 0 0]",
         "[0 1 0]",
         "-119.70884970968915",
         "35.82704675904108",
         "-0.28088138547732344",
         "0.09568470031728676",
         "-0.9549607769000412",
         "0",
         "True",
         "-0.7146476346465247",
         "-2.3475716275506944",
         "-0.4241601868975256",
         "-0.5364486322899894",
         "-0.7589459921565712",
         "-1.0416500651805396"
        ]
       ],
       "shape": {
        "columns": 45,
        "rows": 3659
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>use_case</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>geometry</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>related</th>\n",
       "      <th>x</th>\n",
       "      <th>...</th>\n",
       "      <th>sphere_y</th>\n",
       "      <th>sphere_z</th>\n",
       "      <th>int_label</th>\n",
       "      <th>valid</th>\n",
       "      <th>event_distance_km_norm</th>\n",
       "      <th>event_distance_h_norm</th>\n",
       "      <th>n_disaster_tweets_1km_norm</th>\n",
       "      <th>n_disaster_tweets_10km_norm</th>\n",
       "      <th>n_disaster_tweets_50km_norm</th>\n",
       "      <th>n_disaster_tweets_10000km_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.296800e+18</td>\n",
       "      <td>2020-08-21 13:40:45</td>\n",
       "      <td>California 🔥</td>\n",
       "      <td>Closed due to the czu august lightning complex...</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-122.36110 37.16663)</td>\n",
       "      <td>None</td>\n",
       "      <td>Closed due to the czu august lightning complex...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.362118e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>-0.954961</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.457531</td>\n",
       "      <td>-0.099120</td>\n",
       "      <td>-0.370997</td>\n",
       "      <td>-0.451317</td>\n",
       "      <td>0.758702</td>\n",
       "      <td>1.366236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.417100e+18</td>\n",
       "      <td>2021-07-19 12:23:18</td>\n",
       "      <td>Germany 🌊</td>\n",
       "      <td>Mich beunruhigt nichts mehr.Wir sorgen persönl...</td>\n",
       "      <td>de</td>\n",
       "      <td>POINT (12.22671 51.84923)</td>\n",
       "      <td>None</td>\n",
       "      <td>Mich beunruhigt nichts mehr.Wir sorgen persönl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.361556e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645793</td>\n",
       "      <td>0.288072</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.300809</td>\n",
       "      <td>0.095609</td>\n",
       "      <td>0.362793</td>\n",
       "      <td>0.052028</td>\n",
       "      <td>-0.467472</td>\n",
       "      <td>1.510834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.341270e+18</td>\n",
       "      <td>2020-12-22 06:29:24</td>\n",
       "      <td>California 🔥</td>\n",
       "      <td>The view out my kitchen window of the massive ...</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-118.41191 34.02069)</td>\n",
       "      <td>None</td>\n",
       "      <td>The view out my kitchen window of the massive ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.318155e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>-0.954961</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.714648</td>\n",
       "      <td>0.772862</td>\n",
       "      <td>0.798591</td>\n",
       "      <td>0.527691</td>\n",
       "      <td>-0.172292</td>\n",
       "      <td>-0.719290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320860e+18</td>\n",
       "      <td>2020-10-26 22:49:26</td>\n",
       "      <td>California 🔥</td>\n",
       "      <td>@user @user @user I love 1/2 miles from Anahei...</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-117.85109 33.84275)</td>\n",
       "      <td>None</td>\n",
       "      <td>@ZestForLifeNow @City_of_Anaheim @AnaheimFire ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.311912e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>-0.954961</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.714648</td>\n",
       "      <td>-0.099120</td>\n",
       "      <td>-0.105182</td>\n",
       "      <td>-0.068227</td>\n",
       "      <td>0.592908</td>\n",
       "      <td>-0.276396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.296050e+18</td>\n",
       "      <td>2020-08-19 11:26:50</td>\n",
       "      <td>California 🔥</td>\n",
       "      <td>Someone fucking set off my apartment building’...</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-118.41191 34.02069)</td>\n",
       "      <td>None</td>\n",
       "      <td>Someone fucking set off my apartment building’...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.318155e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>-0.954961</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.714648</td>\n",
       "      <td>0.852190</td>\n",
       "      <td>2.446648</td>\n",
       "      <td>1.889790</td>\n",
       "      <td>1.001015</td>\n",
       "      <td>0.244985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>1.624650e+18</td>\n",
       "      <td>2023-02-12 06:18:19</td>\n",
       "      <td>Turkey 🪨</td>\n",
       "      <td>Hatay/Hassa'da en kazın altında çıkan not...#d...</td>\n",
       "      <td>tr</td>\n",
       "      <td>POINT (36.51252 36.78301)</td>\n",
       "      <td>http://pbs.twimg.com/media/FovuSvIX0AUnSdz.jpg</td>\n",
       "      <td>Hatay/Hassa'da en kazın altında çıkan not...\\r...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.064655e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317761</td>\n",
       "      <td>0.887312</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.168961</td>\n",
       "      <td>-0.188440</td>\n",
       "      <td>-0.317823</td>\n",
       "      <td>-0.436595</td>\n",
       "      <td>0.543710</td>\n",
       "      <td>2.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>1.610290e+18</td>\n",
       "      <td>2023-01-03 15:19:57</td>\n",
       "      <td>Turkey 🪨</td>\n",
       "      <td>FutBol Sohbet programımızın yeni bölümü YouTub...</td>\n",
       "      <td>tr</td>\n",
       "      <td>POINT (33.78141 41.38023)</td>\n",
       "      <td>http://pbs.twimg.com/media/FljqrPJWQAcU-DW.jpg</td>\n",
       "      <td>FutBol Sohbet programımızın yeni bölümü YouTub...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.760672e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317761</td>\n",
       "      <td>0.887312</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.882802</td>\n",
       "      <td>-2.645158</td>\n",
       "      <td>-0.544401</td>\n",
       "      <td>-0.635649</td>\n",
       "      <td>-0.646982</td>\n",
       "      <td>-1.109802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>1.627130e+18</td>\n",
       "      <td>2023-02-19 02:12:45</td>\n",
       "      <td>Chile 🔥</td>\n",
       "      <td>Pasando ahora 😭😭 #Coronel #Biobio #IncendioFor...</td>\n",
       "      <td>es</td>\n",
       "      <td>POINT (-73.22220 -37.00482)</td>\n",
       "      <td>http://pbs.twimg.com/ext_tw_video_thumb/162712...</td>\n",
       "      <td>Pasando ahora 😭😭 #Coronel #Biobio #IncendioFor...</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.154494e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869559</td>\n",
       "      <td>0.356159</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.312896</td>\n",
       "      <td>0.300568</td>\n",
       "      <td>-0.480332</td>\n",
       "      <td>-0.410065</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>0.021594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>1.416140e+18</td>\n",
       "      <td>2021-07-16 21:10:24</td>\n",
       "      <td>Germany 🌊</td>\n",
       "      <td>Rhein unterspült Uferstrasse in Basel und löst...</td>\n",
       "      <td>de</td>\n",
       "      <td>POINT (7.65276 47.57676)</td>\n",
       "      <td>None</td>\n",
       "      <td>Rhein unterspült Uferstrasse in Basel und löst...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.524011e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645793</td>\n",
       "      <td>0.288072</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.852110</td>\n",
       "      <td>-0.180118</td>\n",
       "      <td>-0.141470</td>\n",
       "      <td>-0.150951</td>\n",
       "      <td>-0.432042</td>\n",
       "      <td>0.471640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>1.291310e+18</td>\n",
       "      <td>2020-08-06 09:53:20</td>\n",
       "      <td>California 🔥</td>\n",
       "      <td>My friend was trying 2 b a wingman so she went...</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-122.55544 38.09334)</td>\n",
       "      <td>None</td>\n",
       "      <td>My friend was trying 2 b a wingman so she went...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.364281e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>-0.954961</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.394562</td>\n",
       "      <td>-1.093060</td>\n",
       "      <td>-0.424160</td>\n",
       "      <td>-0.536449</td>\n",
       "      <td>-0.758946</td>\n",
       "      <td>-1.041650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3659 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        message_id                date      use_case  \\\n",
       "0     1.296800e+18 2020-08-21 13:40:45  California 🔥   \n",
       "1     1.417100e+18 2021-07-19 12:23:18     Germany 🌊   \n",
       "2     1.341270e+18 2020-12-22 06:29:24  California 🔥   \n",
       "3     1.320860e+18 2020-10-26 22:49:26  California 🔥   \n",
       "4     1.296050e+18 2020-08-19 11:26:50  California 🔥   \n",
       "...            ...                 ...           ...   \n",
       "3654  1.624650e+18 2023-02-12 06:18:19      Turkey 🪨   \n",
       "3655  1.610290e+18 2023-01-03 15:19:57      Turkey 🪨   \n",
       "3656  1.627130e+18 2023-02-19 02:12:45       Chile 🔥   \n",
       "3657  1.416140e+18 2021-07-16 21:10:24     Germany 🌊   \n",
       "3658  1.291310e+18 2020-08-06 09:53:20  California 🔥   \n",
       "\n",
       "                                                   text tweet_lang  \\\n",
       "0     Closed due to the czu august lightning complex...       None   \n",
       "1     Mich beunruhigt nichts mehr.Wir sorgen persönl...         de   \n",
       "2     The view out my kitchen window of the massive ...       None   \n",
       "3     @user @user @user I love 1/2 miles from Anahei...       None   \n",
       "4     Someone fucking set off my apartment building’...       None   \n",
       "...                                                 ...        ...   \n",
       "3654  Hatay/Hassa'da en kazın altında çıkan not...#d...         tr   \n",
       "3655  FutBol Sohbet programımızın yeni bölümü YouTub...         tr   \n",
       "3656  Pasando ahora 😭😭 #Coronel #Biobio #IncendioFor...         es   \n",
       "3657  Rhein unterspült Uferstrasse in Basel und löst...         de   \n",
       "3658  My friend was trying 2 b a wingman so she went...       None   \n",
       "\n",
       "                         geometry  \\\n",
       "0     POINT (-122.36110 37.16663)   \n",
       "1       POINT (12.22671 51.84923)   \n",
       "2     POINT (-118.41191 34.02069)   \n",
       "3     POINT (-117.85109 33.84275)   \n",
       "4     POINT (-118.41191 34.02069)   \n",
       "...                           ...   \n",
       "3654    POINT (36.51252 36.78301)   \n",
       "3655    POINT (33.78141 41.38023)   \n",
       "3656  POINT (-73.22220 -37.00482)   \n",
       "3657     POINT (7.65276 47.57676)   \n",
       "3658  POINT (-122.55544 38.09334)   \n",
       "\n",
       "                                              photo_url  \\\n",
       "0                                                  None   \n",
       "1                                                  None   \n",
       "2                                                  None   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "3654     http://pbs.twimg.com/media/FovuSvIX0AUnSdz.jpg   \n",
       "3655     http://pbs.twimg.com/media/FljqrPJWQAcU-DW.jpg   \n",
       "3656  http://pbs.twimg.com/ext_tw_video_thumb/162712...   \n",
       "3657                                               None   \n",
       "3658                                               None   \n",
       "\n",
       "                                               text_raw  related  \\\n",
       "0     Closed due to the czu august lightning complex...        1   \n",
       "1     Mich beunruhigt nichts mehr.Wir sorgen persönl...        1   \n",
       "2     The view out my kitchen window of the massive ...        1   \n",
       "3     @ZestForLifeNow @City_of_Anaheim @AnaheimFire ...        1   \n",
       "4     Someone fucking set off my apartment building’...        1   \n",
       "...                                                 ...      ...   \n",
       "3654  Hatay/Hassa'da en kazın altında çıkan not...\\r...        1   \n",
       "3655  FutBol Sohbet programımızın yeni bölümü YouTub...        0   \n",
       "3656  Pasando ahora 😭😭 #Coronel #Biobio #IncendioFor...        1   \n",
       "3657  Rhein unterspült Uferstrasse in Basel und löst...        1   \n",
       "3658  My friend was trying 2 b a wingman so she went...        0   \n",
       "\n",
       "                 x  ...  sphere_y  sphere_z int_label valid  \\\n",
       "0    -1.362118e+07  ...  0.095685 -0.954961         1  True   \n",
       "1     1.361556e+06  ...  0.645793  0.288072         1  True   \n",
       "2    -1.318155e+07  ...  0.095685 -0.954961         2  True   \n",
       "3    -1.311912e+07  ...  0.095685 -0.954961         2  True   \n",
       "4    -1.318155e+07  ...  0.095685 -0.954961         0  True   \n",
       "...            ...  ...       ...       ...       ...   ...   \n",
       "3654  4.064655e+06  ... -0.317761  0.887312         2  True   \n",
       "3655  3.760672e+06  ... -0.317761  0.887312         0  True   \n",
       "3656 -8.154494e+06  ...  0.869559  0.356159         2  True   \n",
       "3657  8.524011e+05  ...  0.645793  0.288072         1  True   \n",
       "3658 -1.364281e+07  ...  0.095685 -0.954961         0  True   \n",
       "\n",
       "     event_distance_km_norm event_distance_h_norm  n_disaster_tweets_1km_norm  \\\n",
       "0                 -0.457531             -0.099120                   -0.370997   \n",
       "1                  1.300809              0.095609                    0.362793   \n",
       "2                 -0.714648              0.772862                    0.798591   \n",
       "3                 -0.714648             -0.099120                   -0.105182   \n",
       "4                 -0.714648              0.852190                    2.446648   \n",
       "...                     ...                   ...                         ...   \n",
       "3654              -1.168961             -0.188440                   -0.317823   \n",
       "3655               0.882802             -2.645158                   -0.544401   \n",
       "3656              -0.312896              0.300568                   -0.480332   \n",
       "3657               0.852110             -0.180118                   -0.141470   \n",
       "3658              -0.394562             -1.093060                   -0.424160   \n",
       "\n",
       "     n_disaster_tweets_10km_norm n_disaster_tweets_50km_norm  \\\n",
       "0                      -0.451317                    0.758702   \n",
       "1                       0.052028                   -0.467472   \n",
       "2                       0.527691                   -0.172292   \n",
       "3                      -0.068227                    0.592908   \n",
       "4                       1.889790                    1.001015   \n",
       "...                          ...                         ...   \n",
       "3654                   -0.436595                    0.543710   \n",
       "3655                   -0.635649                   -0.646982   \n",
       "3656                   -0.410065                    0.183655   \n",
       "3657                   -0.150951                   -0.432042   \n",
       "3658                   -0.536449                   -0.758946   \n",
       "\n",
       "     n_disaster_tweets_10000km_norm  \n",
       "0                          1.366236  \n",
       "1                          1.510834  \n",
       "2                         -0.719290  \n",
       "3                         -0.276396  \n",
       "4                          0.244985  \n",
       "...                             ...  \n",
       "3654                       2.060679  \n",
       "3655                      -1.109802  \n",
       "3656                       0.021594  \n",
       "3657                       0.471640  \n",
       "3658                      -1.041650  \n",
       "\n",
       "[3659 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gdf: gpd.GeoDataFrame = gpd.read_parquet(os.path.join(DATA_PATH, 'processed', 'fine_tuning', 'train_data.parquet'))\n",
    "test_gdf: gpd.GeoDataFrame = gpd.read_parquet(os.path.join(DATA_PATH, 'processed', 'fine_tuning', 'test_data.parquet'))\n",
    "with open(os.path.join(DATA_PATH, 'processed', 'fine_tuning', 'train_label_encoder.pkl'), 'rb') as f:\n",
    "    label_encoder: OrdinalEncoder = pickle.load(f)\n",
    "\n",
    "NON_TEXT_COLUMNS: list[str] = [\n",
    "    'event_distance_km',\n",
    "    'event_distance_h',\n",
    "    'n_disaster_tweets_1km',\n",
    "    'n_disaster_tweets_10km',\n",
    "    'n_disaster_tweets_50km',\n",
    "    'n_disaster_tweets_10000km'\n",
    "]\n",
    "NON_TEXT_COLUMNS_NORM: list[str] = [f'{x}_norm' for x in NON_TEXT_COLUMNS]\n",
    "\n",
    "# Now you can use the loaded label encoder\n",
    "print(\"Class encodings:\", label_encoder.categories[0])\n",
    "print(train_gdf.shape)\n",
    "print(test_gdf.shape)\n",
    "pd.DataFrame(train_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Out-of-fold Preparation\n",
    "With the data prepared, we can try to train an ensemble of (1) a text model and (2) a non-text model using the out-of-fold (OOF) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the event and location encoding options\n",
    "encoding_options = {\n",
    "    \"none\": lambda df: np.empty((df.shape[0], 0)),  # returns an empty array so hstack works\n",
    "    \"event_type_encoding\": lambda df: np.vstack(df['event_type_encoding'].values),\n",
    "    \"sphere_coords\": lambda df: df[['sphere_x', 'sphere_y', 'sphere_z']].values,\n",
    "    \"all\": lambda df: np.hstack([\n",
    "        np.vstack(df['event_type_encoding'].values),\n",
    "        df[['sphere_x', 'sphere_y', 'sphere_z']].values\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Models to evaluate for the non-text features\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(random_state=1),\n",
    "    \"random_forest\": RandomForestClassifier(random_state=2),\n",
    "    \"svm\": SVC(probability=True, random_state=3),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(random_state=5),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"naive_bayes\": GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also prepare the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3659, 12) (3659,)\n",
      "(915, 12) (915,)\n"
     ]
    }
   ],
   "source": [
    "# Construct the feature matrix for the training data\n",
    "X_base_train: np.ndarray = train_gdf[NON_TEXT_COLUMNS].values  # base features\n",
    "X_event_train: np.ndarray = encoding_options['all'](train_gdf)  # event encoding features\n",
    "X_train_non_text: np.ndarray = np.hstack([X_base_train, X_event_train])\n",
    "X_train_text: np.ndarray = train_gdf['text'].values\n",
    "y_train: np.ndarray = train_gdf['int_label'].values\n",
    "\n",
    "# Construct the feature matrix for the test data\n",
    "X_base_test: np.ndarray = test_gdf[NON_TEXT_COLUMNS].values  # base features\n",
    "X_event_test: np.ndarray = encoding_options['all'](test_gdf)  # event encoding features\n",
    "X_test_text: np.ndarray = test_gdf['text'].values\n",
    "X_test_non_text: np.ndarray = np.hstack([X_base_test, X_event_test])\n",
    "y_test: np.ndarray = test_gdf['int_label'].values\n",
    "\n",
    "print(X_train_non_text.shape, X_train_text.shape)\n",
    "print(X_test_non_text.shape, X_test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then repeatedly train models on four folds and predict for the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted non-text model (random forest) with validation macro F1: 0.6869042751741713\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2, 'verbose': 0, 'warm_start': False}\n",
      "Fitted non-text model (random forest) with validation macro F1: 0.6958871168875864\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2, 'verbose': 0, 'warm_start': False}\n",
      "Fitted non-text model (random forest) with validation macro F1: 0.6941731506171892\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2, 'verbose': 0, 'warm_start': False}\n",
      "Fitted non-text model (random forest) with validation macro F1: 0.6888540497678094\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2, 'verbose': 0, 'warm_start': False}\n",
      "Fitted non-text model (random forest) with validation macro F1: 0.6924271594200981\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2, 'verbose': 0, 'warm_start': False}\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0.06975397 0.36894048 0.56130556]\n",
      " [0.01821429 0.97311905 0.00866667]\n",
      " [0.49435714 0.41577381 0.08986905]\n",
      " [0.14735317 0.38259921 0.47004762]\n",
      " [0.24007937 0.45977778 0.30014286]]\n"
     ]
    }
   ],
   "source": [
    "# Define the folds for stacking\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store out-of-fold predicted probabilities for each base model\n",
    "oof_preds_nontext = np.zeros((X_train_non_text.shape[0], len(train_gdf['int_label'].unique())))\n",
    "oof_features_nontext = np.zeros((X_train_non_text.shape[0], X_train_non_text.shape[1]))\n",
    "oof_preds_text = np.zeros((X_train_non_text.shape[0], len(train_gdf['int_label'].unique())))\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_non_text, y_train):\n",
    "    # Split data for both non-text and text features\n",
    "    X_train_non_text_kf, X_val_non_text_kf = X_train_non_text[train_idx], X_train_non_text[val_idx]\n",
    "    X_train_text_kf, X_val_text_kf = X_train_text[train_idx], X_train_text[val_idx]\n",
    "    y_train_kf, y_val_kf = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    X_train_text_kf_bert, X_val_text_kf_bert, y_train_kf_bert, y_val_kf_bert = train_test_split(\n",
    "        X_train_text_kf, y_train_kf, test_size=0.2, random_state=1\n",
    "    )\n",
    "\n",
    "    # Fit a BERT classification model for the text features\n",
    "    model, tokenizer, eval_results = train_classifier(\n",
    "        texts_train=X_train_text_kf_bert.tolist(),\n",
    "        texts_val=X_val_text_kf_bert.tolist(),\n",
    "        y_train=y_train_kf_bert.tolist(),\n",
    "        y_val=y_val_kf_bert.tolist(),\n",
    "        model_name='Twitter/twhin-bert-base',\n",
    "        model_path=os.path.join(DATA_PATH, 'models', f'twhin-bert-base_ft_kf', 'model'),\n",
    "        logging_path=os.path.join(DATA_PATH, 'models', f'twhin-bert-base_ft_kf', 'logs'),\n",
    "        weighted_loss=False,\n",
    "        id2label={i: label for i, label in enumerate(label_encoder.categories[0])},\n",
    "        label2id={label: i for i, label in enumerate(label_encoder.categories[0])},\n",
    "        learning_rate=0.00004657782284000393,\n",
    "        weight_decay=0.06513203428915136,\n",
    "        epochs=5,\n",
    "        batch_size=16\n",
    "    )\n",
    "    print(f'Validation macro F1 for text model: {eval_results}')\n",
    "\n",
    "    # Create a text classification pipeline using your fine-tuned model and tokenizer\n",
    "    classifier = pipeline(\"text-classification\", model=os.path.join(DATA_PATH, 'models', f'twhin-bert-base_ft_kf', 'model'), \n",
    "                          device=device, return_all_scores=True)\n",
    "    \n",
    "    # Make OOF predictions using the trained text model\n",
    "    text_predictions: list = []\n",
    "    for text in X_val_text_kf.tolist():\n",
    "        text_predictions.append(extract_probabilities(text=text, classifier=classifier))\n",
    "    text_prediction_df: pd.DataFrame = pd.DataFrame.from_dict(text_predictions)\n",
    "    oof_preds_text[val_idx, :] = text_prediction_df[['p_not_related', 'p_related_but_not_relevant',\n",
    "                                                     'p_related_and_relevant']].values\n",
    "    \n",
    "    # Next, train a model on the non-text features with parametrisation based from the non-text evaluation\n",
    "    non_text_model, non_text_params, non_text_f1 = evaluate_model(\n",
    "        RandomForestClassifier(random_state=2, n_estimators=100, max_depth=None, min_samples_split=5), \n",
    "        X=X_train_non_text_kf, y=y_train_kf\n",
    "    )\n",
    "    print(f'Fitted non-text model (random forest) with validation macro F1: {non_text_f1}')\n",
    "    print(non_text_params)\n",
    "\n",
    "    # Get the OOF predictions for the non-text model\n",
    "    oof_preds_nontext[val_idx, :] = non_text_model.predict_proba(X_val_non_text_kf)\n",
    "\n",
    "print(oof_preds_text[:5])\n",
    "print(oof_preds_nontext[:5])\n",
    "\n",
    "# Store the OOF predictions for later\n",
    "np.save(os.path.join(RESULTS_PATH, 'classif_head', 'oof_preds_text.npy'), oof_preds_text)\n",
    "np.save(os.path.join(RESULTS_PATH, 'classif_head', 'oof_preds_nontext.npy'), oof_preds_nontext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the out-of-fold predictions to train a set of meta classifiers.\n",
    "\n",
    "## 2. Meta Model Training\n",
    "First, we go ahead and train a full ensemble based on the OOF prediction probabilities. We also train a partial meta model that is based on the text OOF predictions and the non-text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.74210154e-04 9.94033277e-01 4.99257911e-03]\n",
      " [1.30112341e-03 9.97927666e-01 7.71237537e-04]\n",
      " [3.79778771e-03 4.16162517e-03 9.92040575e-01]\n",
      " [7.70559013e-01 8.05612747e-03 2.21384898e-01]\n",
      " [9.98559773e-01 3.94126022e-04 1.04616175e-03]]\n",
      "[[0.06975397 0.36894048 0.56130556]\n",
      " [0.01821429 0.97311905 0.00866667]\n",
      " [0.49435714 0.41577381 0.08986905]\n",
      " [0.14735317 0.38259921 0.47004762]\n",
      " [0.24007937 0.45977778 0.30014286]]\n",
      "(3659, 6)\n",
      "(3659, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:09<00:00, 31.50s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "cv_macro_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c46bac1d-de29-49e1-aa00-3a971f8ef6a5",
       "rows": [
        [
         "0",
         "logistic_regression",
         "probabilities",
         "{'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}",
         "0.8131801113634781",
         "LogisticRegression(C=10, max_iter=1000, random_state=1, solver='saga')"
        ],
        [
         "1",
         "logistic_regression",
         "partial",
         "{'C': 10, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs'}",
         "0.8113932527439713",
         "LogisticRegression(C=10, max_iter=2000, random_state=1)"
        ],
        [
         "2",
         "random_forest",
         "probabilities",
         "{'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}",
         "0.8136631541337683",
         "RandomForestClassifier(max_depth=10, min_samples_split=5, random_state=2)"
        ],
        [
         "3",
         "random_forest",
         "partial",
         "{'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}",
         "0.8174971085474156",
         "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=200,\n                       random_state=2)"
        ],
        [
         "4",
         "svm",
         "probabilities",
         "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}",
         "0.8086506817840222",
         "SVC(C=10, probability=True, random_state=3)"
        ],
        [
         "5",
         "svm",
         "partial",
         "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}",
         "0.5650733587602892",
         "SVC(C=10, probability=True, random_state=3)"
        ],
        [
         "6",
         "gradient_boosting",
         "probabilities",
         "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}",
         "0.8107169544145112",
         "GradientBoostingClassifier(n_estimators=50, random_state=5)"
        ],
        [
         "7",
         "gradient_boosting",
         "partial",
         "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}",
         "0.8145702873310963",
         "GradientBoostingClassifier(learning_rate=0.01, n_estimators=200, random_state=5)"
        ],
        [
         "8",
         "knn",
         "probabilities",
         "{'n_neighbors': 9, 'weights': 'uniform'}",
         "0.8114459657564854",
         "KNeighborsClassifier(n_neighbors=9)"
        ],
        [
         "9",
         "knn",
         "partial",
         "{'n_neighbors': 9, 'weights': 'distance'}",
         "0.6629695091026117",
         "KNeighborsClassifier(n_neighbors=9, weights='distance')"
        ],
        [
         "10",
         "naive_bayes",
         "probabilities",
         "{'var_smoothing': 1e-09}",
         "0.8041754125845607",
         "GaussianNB()"
        ],
        [
         "11",
         "naive_bayes",
         "partial",
         "{'var_smoothing': 1e-09}",
         "0.7438149305360034",
         "GaussianNB()"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>method</th>\n",
       "      <th>params</th>\n",
       "      <th>cv_macro_f1</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>{'C': 10, 'max_iter': 1000, 'penalty': 'l2', '...</td>\n",
       "      <td>0.813180</td>\n",
       "      <td>LogisticRegression(C=10, max_iter=1000, random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>partial</td>\n",
       "      <td>{'C': 10, 'max_iter': 2000, 'penalty': 'l2', '...</td>\n",
       "      <td>0.811393</td>\n",
       "      <td>LogisticRegression(C=10, max_iter=2000, random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.813663</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>partial</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.817497</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.808651</td>\n",
       "      <td>SVC(C=10, probability=True, random_state=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm</td>\n",
       "      <td>partial</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.565073</td>\n",
       "      <td>SVC(C=10, probability=True, random_state=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.810717</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>partial</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>knn</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'uniform'}</td>\n",
       "      <td>0.811446</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>partial</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "      <td>0.662970</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=9, weights='d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>{'var_smoothing': 1e-09}</td>\n",
       "      <td>0.804175</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>partial</td>\n",
       "      <td>{'var_smoothing': 1e-09}</td>\n",
       "      <td>0.743815</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name         method  \\\n",
       "0   logistic_regression  probabilities   \n",
       "1   logistic_regression        partial   \n",
       "2         random_forest  probabilities   \n",
       "3         random_forest        partial   \n",
       "4                   svm  probabilities   \n",
       "5                   svm        partial   \n",
       "6     gradient_boosting  probabilities   \n",
       "7     gradient_boosting        partial   \n",
       "8                   knn  probabilities   \n",
       "9                   knn        partial   \n",
       "10          naive_bayes  probabilities   \n",
       "11          naive_bayes        partial   \n",
       "\n",
       "                                               params  cv_macro_f1  \\\n",
       "0   {'C': 10, 'max_iter': 1000, 'penalty': 'l2', '...     0.813180   \n",
       "1   {'C': 10, 'max_iter': 2000, 'penalty': 'l2', '...     0.811393   \n",
       "2   {'max_depth': 10, 'min_samples_split': 5, 'n_e...     0.813663   \n",
       "3   {'max_depth': 10, 'min_samples_split': 5, 'n_e...     0.817497   \n",
       "4        {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}     0.808651   \n",
       "5        {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}     0.565073   \n",
       "6   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...     0.810717   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...     0.814570   \n",
       "8            {'n_neighbors': 9, 'weights': 'uniform'}     0.811446   \n",
       "9           {'n_neighbors': 9, 'weights': 'distance'}     0.662970   \n",
       "10                           {'var_smoothing': 1e-09}     0.804175   \n",
       "11                           {'var_smoothing': 1e-09}     0.743815   \n",
       "\n",
       "                                                model  \n",
       "0   LogisticRegression(C=10, max_iter=1000, random...  \n",
       "1   LogisticRegression(C=10, max_iter=2000, random...  \n",
       "2   (DecisionTreeClassifier(max_depth=10, max_feat...  \n",
       "3   (DecisionTreeClassifier(max_depth=10, max_feat...  \n",
       "4         SVC(C=10, probability=True, random_state=3)  \n",
       "5         SVC(C=10, probability=True, random_state=3)  \n",
       "6   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "7   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "8                 KNeighborsClassifier(n_neighbors=9)  \n",
       "9   KNeighborsClassifier(n_neighbors=9, weights='d...  \n",
       "10                                       GaussianNB()  \n",
       "11                                       GaussianNB()  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_preds_text = np.load(os.path.join(RESULTS_PATH, 'classif_head', 'oof_preds_text.npy'))\n",
    "oof_preds_nontext = np.load(os.path.join(RESULTS_PATH, 'classif_head', 'oof_preds_nontext.npy'))\n",
    "\n",
    "print(oof_preds_text[:5])\n",
    "print(oof_preds_nontext[:5])\n",
    "\n",
    "meta_training_results: list[dict] = []\n",
    "\n",
    "# Features based on probabilities\n",
    "meta_prob_features_train: np.ndarray = np.concatenate([oof_preds_nontext, oof_preds_text], axis=1)  # shape: [n_train, 2*n_classes]\n",
    "print(meta_prob_features_train.shape)\n",
    "\n",
    "# Features based on text probabilities and non-text features\n",
    "meta_part_features_train: np.ndarray = np.concatenate([X_train_non_text, oof_preds_text], axis=1)  # shape: [n_train, n_classes+9]\n",
    "print(meta_part_features_train.shape)\n",
    "\n",
    "# Fit and store all models\n",
    "for model_name, model in tqdm(models.items()):\n",
    "    # Train a model on the OOF probabilities only\n",
    "    prob_meta_model, prob_meta_params, prob_meta_f1 = optimise_model(model, meta_prob_features_train, y_train)\n",
    "    meta_training_results.append({\n",
    "        'model_name': model_name,\n",
    "        'method': 'probabilities',\n",
    "        'params': prob_meta_params,\n",
    "        'cv_macro_f1': prob_meta_f1,\n",
    "        'model': prob_meta_model\n",
    "    })\n",
    "\n",
    "    # Train a model on the OOF probabilities of the text model and the non-text features\n",
    "    part_meta_model, part_meta_params, part_meta_f1 = optimise_model(model, meta_part_features_train, y_train)\n",
    "    meta_training_results.append({\n",
    "        'model_name': model_name,\n",
    "        'method': 'partial',\n",
    "        'params': part_meta_params,\n",
    "        'cv_macro_f1': part_meta_f1,\n",
    "        'model': part_meta_model\n",
    "    })\n",
    "\n",
    "meta_result_df: pd.DataFrame = pd.DataFrame.from_dict(meta_training_results)\n",
    "meta_result_df.to_csv(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learner_validation.csv'), index=False)\n",
    "with open(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learner_models.pickle'), 'wb') as f:\n",
    "    pickle.dump(meta_training_results, f)\n",
    "meta_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also try to do the equivalent per use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Train a model for each \\'use_case\\' in the training data using meta_part_features_train\\noof_preds_text = np.load(os.path.join(RESULTS_PATH, \\'classif_head\\', \\'oof_preds_text.npy\\'))\\noof_preds_nontext = np.load(os.path.join(RESULTS_PATH, \\'classif_head\\', \\'oof_preds_nontext.npy\\'))\\n\\n# Features based on text probabilities and non-text features\\nmeta_part_features_train_use_case: np.ndarray = np.concatenate([X_base_train, oof_preds_text], axis=1)  # shape: [n_train, n_classes+9]\\nprint(meta_part_features_train_use_case.shape)\\n\\n# Get unique use cases from the training dataframe\\nunique_use_cases = train_gdf[\\'use_case\\'].unique()\\nmeta_training_results_by_use_case = []\\n\\nfor use_case in unique_use_cases:\\n    # Create a boolean mask for the current use_case\\n    use_case_mask = train_gdf[\\'use_case\\'] == use_case\\n    \\n    # Filter the feature matrix and labels for the current use_case\\n    X_use_case = meta_part_features_train_use_case[use_case_mask]\\n    y_use_case = y_train[use_case_mask]\\n    \\n    # print(f\"Training models for use_case: {use_case}\")\\n    # Iterate over the models and train on the use_case-specific data\\n    for model_name, model in tqdm(models.items(), desc=f\"Use case {use_case}\"):\\n        use_case_model, use_case_params, use_case_f1 = optimise_model(model, X_use_case, y_use_case)\\n        meta_training_results_by_use_case.append({\\n            \\'use_case\\': use_case,\\n            \\'model_name\\': model_name,\\n            \\'method\\': \\'partial\\',\\n            \\'params\\': use_case_params,\\n            \\'cv_macro_f1\\': use_case_f1,\\n            \\'model\\': use_case_model\\n        })\\n\\n# Convert results to a DataFrame and save to CSV\\nmeta_result_by_use_case_df = pd.DataFrame.from_dict(meta_training_results_by_use_case)\\nmeta_result_by_use_case_df.to_csv(os.path.join(RESULTS_PATH, \\'classif_head\\', \\'meta_learner_validation_by_use_case.csv\\'), index=False)\\nwith open(os.path.join(RESULTS_PATH, \\'classif_head\\', \\'meta_learner_models_per_use_case.pickle\\'), \\'wb\\') as f:\\n    pickle.dump(meta_training_results_by_use_case, f)\\n\\n# Display the resulting DataFrame\\nmeta_result_by_use_case_df\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# please do not run this, it's a waste of time\n",
    "\"\"\"\n",
    "# Train a model for each 'use_case' in the training data using meta_part_features_train\n",
    "oof_preds_text = np.load(os.path.join(RESULTS_PATH, 'classif_head', 'oof_preds_text.npy'))\n",
    "oof_preds_nontext = np.load(os.path.join(RESULTS_PATH, 'classif_head', 'oof_preds_nontext.npy'))\n",
    "\n",
    "# Features based on text probabilities and non-text features\n",
    "meta_part_features_train_use_case: np.ndarray = np.concatenate([X_base_train, oof_preds_text], axis=1)  # shape: [n_train, n_classes+9]\n",
    "print(meta_part_features_train_use_case.shape)\n",
    "\n",
    "# Get unique use cases from the training dataframe\n",
    "unique_use_cases = train_gdf['use_case'].unique()\n",
    "meta_training_results_by_use_case = []\n",
    "\n",
    "for use_case in unique_use_cases:\n",
    "    # Create a boolean mask for the current use_case\n",
    "    use_case_mask = train_gdf['use_case'] == use_case\n",
    "    \n",
    "    # Filter the feature matrix and labels for the current use_case\n",
    "    X_use_case = meta_part_features_train_use_case[use_case_mask]\n",
    "    y_use_case = y_train[use_case_mask]\n",
    "    \n",
    "    # print(f\"Training models for use_case: {use_case}\")\n",
    "    # Iterate over the models and train on the use_case-specific data\n",
    "    for model_name, model in tqdm(models.items(), desc=f\"Use case {use_case}\"):\n",
    "        use_case_model, use_case_params, use_case_f1 = optimise_model(model, X_use_case, y_use_case)\n",
    "        meta_training_results_by_use_case.append({\n",
    "            'use_case': use_case,\n",
    "            'model_name': model_name,\n",
    "            'method': 'partial',\n",
    "            'params': use_case_params,\n",
    "            'cv_macro_f1': use_case_f1,\n",
    "            'model': use_case_model\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame and save to CSV\n",
    "meta_result_by_use_case_df = pd.DataFrame.from_dict(meta_training_results_by_use_case)\n",
    "meta_result_by_use_case_df.to_csv(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learner_validation_by_use_case.csv'), index=False)\n",
    "with open(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learner_models_per_use_case.pickle'), 'wb') as f:\n",
    "    pickle.dump(meta_training_results_by_use_case, f)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "meta_result_by_use_case_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Ensemble Building\n",
    "Lastly, let's build the full ensemble, using (1) our best text model and (2) our best non-text model. To achieve this, we first need to train individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted non-text model (random forest) with validation macro F1: 0.704437589623365\n",
      "{'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Our text model already has been fine-tuned\n",
    "classifier_full = pipeline(\n",
    "    \"text-classification\", \n",
    "    model=os.path.join(DATA_PATH, 'models', f'twhin-bert-base_ft', 'model'),\n",
    "    device=device, \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# For the non-text model, we should train an optimal one based on the random forest\n",
    "# Here, optimise_model is assumed to be a function that performs hyperparameter tuning\n",
    "non_text_model_full, non_text_params_full, non_text_f1_full = optimise_model(\n",
    "    RandomForestClassifier(random_state=2), X_train_non_text, y_train)\n",
    "print(f'Fitted non-text model (random forest) with validation macro F1: {non_text_f1_full}')\n",
    "print(non_text_params_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get the class probabilities for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(915, 6)\n",
      "(915, 15)\n",
      "(915, 9)\n"
     ]
    }
   ],
   "source": [
    "# 1. Get probabilities from the non-text model for the test set\n",
    "test_preds_nontext = non_text_model_full.predict_proba(X_test_non_text)\n",
    "\n",
    "# 2. Get probabilities from the text model for the test set\n",
    "text_predictions_test = []\n",
    "for text in X_test_text.tolist():\n",
    "    text_predictions_test.append(extract_probabilities(text=text, classifier=classifier_full))\n",
    "text_prediction_df_test = pd.DataFrame.from_dict(text_predictions_test)\n",
    "# Make sure the columns order is the same as in training, e.g., ['p_not_related', 'p_related_but_not_relevant', 'p_related_and_relevant']\n",
    "test_preds_text = text_prediction_df_test[['p_not_related', 'p_related_but_not_relevant', 'p_related_and_relevant']].values\n",
    "\n",
    "# Features based on probabilities\n",
    "meta_prob_features_test: np.ndarray = np.concatenate([test_preds_nontext, test_preds_text], axis=1)  # shape: [n_train, 2*n_classes]\n",
    "print(meta_prob_features_test.shape)\n",
    "\n",
    "# Features based on text probabilities and non-text features\n",
    "meta_part_features_test: np.ndarray = np.concatenate([X_test_non_text, test_preds_text], axis=1)  # shape: [n_train, n_classes+12]\n",
    "print(meta_part_features_test.shape)\n",
    "\n",
    "# Features based on text probabilities and non-text features for use-case specific evaluation\n",
    "meta_part_features_test_use_case: np.ndarray = np.concatenate([X_base_test, test_preds_text], axis=1)  # shape: [n_test, n_classes+12=15]\n",
    "print(meta_part_features_test_use_case.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we are able to apply the meta classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "meta_method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "test_macro_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_macro_rec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_macro_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_roc_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_rmse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_mae",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "82f99a12-452a-4b1c-afba-95f0d4d27057",
       "rows": [
        [
         "0",
         "logistic_regression",
         "probabilities",
         "0.8325006284565107",
         "0.7995914083427356",
         "0.810703988939713",
         "0.8316939890710382",
         "0.9380083237204181",
         "0.48698918873559727",
         "0.1912568306010929"
        ],
        [
         "1",
         "logistic_regression",
         "partial",
         "0.8230537107860151",
         "0.7880317210093254",
         "0.7996296869536307",
         "0.8218579234972677",
         "0.9309012196816305",
         "0.49367585214848775",
         "0.2"
        ],
        [
         "2",
         "random_forest",
         "probabilities",
         "0.7965012084240121",
         "0.7898946546886892",
         "0.7926665195267938",
         "0.8098360655737705",
         "0.9209720349660571",
         "0.5089365318412729",
         "0.21311475409836064"
        ],
        [
         "3",
         "random_forest",
         "partial",
         "0.8318837203610064",
         "0.8019352013767436",
         "0.812523812943981",
         "0.8316939890710382",
         "0.9317823336413361",
         "0.48698918873559727",
         "0.1912568306010929"
        ],
        [
         "4",
         "svm",
         "probabilities",
         "0.8249315794148102",
         "0.7882242962940861",
         "0.7999427077738389",
         "0.8240437158469945",
         "0.9095658702656664",
         "0.49478151053712477",
         "0.1989071038251366"
        ],
        [
         "5",
         "svm",
         "partial",
         "0.6567363759426127",
         "0.594951185954197",
         "0.574859617253957",
         "0.6830601092896175",
         "0.8554587106710213",
         "0.6131527412912752",
         "0.3366120218579235"
        ],
        [
         "6",
         "gradient_boosting",
         "probabilities",
         "0.6999001306513906",
         "0.7050565194252458",
         "0.6993228410811221",
         "0.726775956284153",
         "0.9050025011917211",
         "0.7182248913366336",
         "0.3540983606557377"
        ],
        [
         "7",
         "gradient_boosting",
         "partial",
         "0.8283400399463471",
         "0.8060037785433692",
         "0.814485708749678",
         "0.8316939890710382",
         "0.9273111490195992",
         "0.48361118827087224",
         "0.1901639344262295"
        ],
        [
         "8",
         "knn",
         "probabilities",
         "0.8111690897638842",
         "0.7799692129505472",
         "0.790430260149115",
         "0.8131147540983606",
         "0.9160765073176621",
         "0.5121475197315839",
         "0.21202185792349726"
        ],
        [
         "9",
         "knn",
         "partial",
         "0.6805972082652932",
         "0.672249823846501",
         "0.6755737547317396",
         "0.7016393442622951",
         "0.8575393603576017",
         "0.662830492882669",
         "0.3453551912568306"
        ],
        [
         "10",
         "naive_bayes",
         "probabilities",
         "0.8079455807262569",
         "0.7898697506707871",
         "0.7968926111417428",
         "0.8174863387978142",
         "0.9320193148487622",
         "0.5046234326140329",
         "0.20655737704918034"
        ],
        [
         "11",
         "naive_bayes",
         "partial",
         "0.7620114481118051",
         "0.7662944206672249",
         "0.7621105010182273",
         "0.7781420765027323",
         "0.9095908665977301",
         "0.5801827486731431",
         "0.26010928961748636"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>meta_method</th>\n",
       "      <th>test_macro_prec</th>\n",
       "      <th>test_macro_rec</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.799591</td>\n",
       "      <td>0.810704</td>\n",
       "      <td>0.831694</td>\n",
       "      <td>0.938008</td>\n",
       "      <td>0.486989</td>\n",
       "      <td>0.191257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>partial</td>\n",
       "      <td>0.823054</td>\n",
       "      <td>0.788032</td>\n",
       "      <td>0.799630</td>\n",
       "      <td>0.821858</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.493676</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>0.796501</td>\n",
       "      <td>0.789895</td>\n",
       "      <td>0.792667</td>\n",
       "      <td>0.809836</td>\n",
       "      <td>0.920972</td>\n",
       "      <td>0.508937</td>\n",
       "      <td>0.213115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>partial</td>\n",
       "      <td>0.831884</td>\n",
       "      <td>0.801935</td>\n",
       "      <td>0.812524</td>\n",
       "      <td>0.831694</td>\n",
       "      <td>0.931782</td>\n",
       "      <td>0.486989</td>\n",
       "      <td>0.191257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>0.824932</td>\n",
       "      <td>0.788224</td>\n",
       "      <td>0.799943</td>\n",
       "      <td>0.824044</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.494782</td>\n",
       "      <td>0.198907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm</td>\n",
       "      <td>partial</td>\n",
       "      <td>0.656736</td>\n",
       "      <td>0.594951</td>\n",
       "      <td>0.574860</td>\n",
       "      <td>0.683060</td>\n",
       "      <td>0.855459</td>\n",
       "      <td>0.613153</td>\n",
       "      <td>0.336612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>0.699900</td>\n",
       "      <td>0.705057</td>\n",
       "      <td>0.699323</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.905003</td>\n",
       "      <td>0.718225</td>\n",
       "      <td>0.354098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>partial</td>\n",
       "      <td>0.828340</td>\n",
       "      <td>0.806004</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>0.831694</td>\n",
       "      <td>0.927311</td>\n",
       "      <td>0.483611</td>\n",
       "      <td>0.190164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>knn</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>0.811169</td>\n",
       "      <td>0.779969</td>\n",
       "      <td>0.790430</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.916077</td>\n",
       "      <td>0.512148</td>\n",
       "      <td>0.212022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>partial</td>\n",
       "      <td>0.680597</td>\n",
       "      <td>0.672250</td>\n",
       "      <td>0.675574</td>\n",
       "      <td>0.701639</td>\n",
       "      <td>0.857539</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>0.345355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>probabilities</td>\n",
       "      <td>0.807946</td>\n",
       "      <td>0.789870</td>\n",
       "      <td>0.796893</td>\n",
       "      <td>0.817486</td>\n",
       "      <td>0.932019</td>\n",
       "      <td>0.504623</td>\n",
       "      <td>0.206557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>partial</td>\n",
       "      <td>0.762011</td>\n",
       "      <td>0.766294</td>\n",
       "      <td>0.762111</td>\n",
       "      <td>0.778142</td>\n",
       "      <td>0.909591</td>\n",
       "      <td>0.580183</td>\n",
       "      <td>0.260109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name    meta_method  test_macro_prec  test_macro_rec  \\\n",
       "0   logistic_regression  probabilities         0.832501        0.799591   \n",
       "1   logistic_regression        partial         0.823054        0.788032   \n",
       "2         random_forest  probabilities         0.796501        0.789895   \n",
       "3         random_forest        partial         0.831884        0.801935   \n",
       "4                   svm  probabilities         0.824932        0.788224   \n",
       "5                   svm        partial         0.656736        0.594951   \n",
       "6     gradient_boosting  probabilities         0.699900        0.705057   \n",
       "7     gradient_boosting        partial         0.828340        0.806004   \n",
       "8                   knn  probabilities         0.811169        0.779969   \n",
       "9                   knn        partial         0.680597        0.672250   \n",
       "10          naive_bayes  probabilities         0.807946        0.789870   \n",
       "11          naive_bayes        partial         0.762011        0.766294   \n",
       "\n",
       "    test_macro_f1  test_acc  test_roc_auc  test_rmse  test_mae  \n",
       "0        0.810704  0.831694      0.938008   0.486989  0.191257  \n",
       "1        0.799630  0.821858      0.930901   0.493676  0.200000  \n",
       "2        0.792667  0.809836      0.920972   0.508937  0.213115  \n",
       "3        0.812524  0.831694      0.931782   0.486989  0.191257  \n",
       "4        0.799943  0.824044      0.909566   0.494782  0.198907  \n",
       "5        0.574860  0.683060      0.855459   0.613153  0.336612  \n",
       "6        0.699323  0.726776      0.905003   0.718225  0.354098  \n",
       "7        0.814486  0.831694      0.927311   0.483611  0.190164  \n",
       "8        0.790430  0.813115      0.916077   0.512148  0.212022  \n",
       "9        0.675574  0.701639      0.857539   0.662830  0.345355  \n",
       "10       0.796893  0.817486      0.932019   0.504623  0.206557  \n",
       "11       0.762111  0.778142      0.909591   0.580183  0.260109  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_results: list[dict] = []\n",
    "\n",
    "# Iterate over every possible meta model\n",
    "for meta_config in meta_training_results:\n",
    "    # meta model based on probabilities\n",
    "    if meta_config['method'] == 'probabilities':\n",
    "        predictions: np.ndarray = meta_config['model'].predict(meta_prob_features_test)\n",
    "        probs: np.ndarray = meta_config['model'].predict_proba(meta_prob_features_test)\n",
    "    # meta model based on text probabilities and non-text features\n",
    "    elif meta_config['method'] == 'partial':\n",
    "        predictions: np.ndarray = meta_config['model'].predict(meta_part_features_test)\n",
    "        probs: np.ndarray = meta_config['model'].predict_proba(meta_part_features_test)\n",
    "    test_gdf[f'pred_{meta_config[\"method\"]}_{meta_config[\"model_name\"]}'] = predictions\n",
    "\n",
    "    # Compute all needed evaluation metrics\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(test_gdf['int_label'], predictions, average='macro')\n",
    "    rmse: float = root_mean_squared_error(y_true=test_gdf['int_label'], y_pred=predictions)\n",
    "    mae: float = mean_absolute_error(y_true=test_gdf['int_label'], y_pred=predictions)\n",
    "    roc_auc = roc_auc_score(y_true=test_gdf['int_label'], y_score=probs, multi_class='ovr')\n",
    "    acc = accuracy_score(y_true=test_gdf['int_label'], y_pred=predictions)\n",
    "\n",
    "    meta_results.append({\n",
    "        \"model_name\": meta_config['model_name'],\n",
    "        \"meta_method\": meta_config['method'],\n",
    "        \"test_macro_prec\": prec,\n",
    "        \"test_macro_rec\": rec,\n",
    "        \"test_macro_f1\": f1,\n",
    "        'test_acc': acc,\n",
    "        \"test_roc_auc\": roc_auc,\n",
    "        \"test_rmse\": rmse,\n",
    "        \"test_mae\": mae\n",
    "    })\n",
    "\n",
    "meta_result_df: pd.DataFrame = pd.DataFrame.from_dict(meta_results)\n",
    "meta_result_df.to_csv(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learner_test.csv'), index=False)\n",
    "test_gdf.to_parquet(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learning_preds.parquet'))\n",
    "meta_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, why not do the same thing per use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please do not run this, it's a waste of time, this was just for experimental purposes\n",
    "\"\"\"\n",
    "# Initialize dictionaries to hold global predictions and probabilities for each (model_name, method)\n",
    "global_predictions = {}  # key: (model_name, method), value: numpy array of predictions for all test samples\n",
    "global_probabilities = {}  # key: (model_name, method), value: numpy array of predicted probabilities\n",
    "\n",
    "# First, identify all keys from the use-case–specific meta training results\n",
    "for meta_config in meta_training_results_by_use_case:\n",
    "    key = (meta_config['model_name'], meta_config['method'])\n",
    "    if key not in global_predictions:\n",
    "        # Create an empty array for predictions for all test samples (assumes predictions are int type)\n",
    "        global_predictions[key] = np.empty(len(test_gdf), dtype=int)\n",
    "        # We'll initialize probabilities once we know the number of classes (from the first use case)\n",
    "        global_probabilities[key] = None\n",
    "\n",
    "# Now, iterate over each meta config and fill in predictions for its use case subset\n",
    "for meta_config in meta_training_results_by_use_case:\n",
    "    key = (meta_config['model_name'], meta_config['method'])\n",
    "    use_case = meta_config['use_case']\n",
    "    # Create a boolean mask for test samples belonging to this use case\n",
    "    use_case_mask = test_gdf['use_case'] == use_case\n",
    "    \n",
    "    # Select the appropriate feature matrix based on the method\n",
    "    if meta_config['method'] == 'partial':\n",
    "        X_subset = meta_part_features_test_use_case[use_case_mask]\n",
    "    else:  # For example, if method == 'probabilities'\n",
    "        X_subset = meta_prob_features_test[use_case_mask]\n",
    "    \n",
    "    # Obtain predictions and predicted probabilities on the subset\n",
    "    preds_subset = meta_config['model'].predict(X_subset)\n",
    "    probs_subset = meta_config['model'].predict_proba(X_subset)\n",
    "    \n",
    "    # If the probabilities array for this key is not yet initialized, do it now\n",
    "    if global_probabilities[key] is None:\n",
    "        global_probabilities[key] = np.empty((len(test_gdf), probs_subset.shape[1]))\n",
    "    \n",
    "    # Fill in the predictions and probabilities for these test indices\n",
    "    indices = test_gdf.index[use_case_mask]\n",
    "    global_predictions[key][indices] = preds_subset\n",
    "    global_probabilities[key][indices] = probs_subset\n",
    "\n",
    "# Optionally, add the global predictions to test_gdf as new columns\n",
    "for key, preds in global_predictions.items():\n",
    "    col_name = f'pred_use_case_{key[0]}_{key[1]}'\n",
    "    test_gdf[col_name] = preds\n",
    "\n",
    "# Now that we have predictions for every test sample from each meta model, compute evaluation metrics globally.\n",
    "meta_results_use_case: list[dict] = []\n",
    "for key, preds in global_predictions.items():\n",
    "    probs = global_probabilities[key]\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        test_gdf['int_label'], preds, average='macro'\n",
    "    )\n",
    "    rmse: float = root_mean_squared_error(test_gdf['int_label'], preds)\n",
    "    mae: float = mean_absolute_error(test_gdf['int_label'], preds)\n",
    "    roc_auc = roc_auc_score(test_gdf['int_label'], probs, multi_class='ovr')\n",
    "    acc = accuracy_score(test_gdf['int_label'], preds)\n",
    "\n",
    "    # Compute average confidence for misclassified samples:\n",
    "    misclassified_mask = preds != test_gdf['int_label'].values\n",
    "    if misclassified_mask.sum() > 0:\n",
    "        mis_confidences = [probs[i, preds[i]] for i in np.where(misclassified_mask)[0]]\n",
    "        avg_mis_conf = np.mean(mis_confidences)\n",
    "    else:\n",
    "        avg_mis_conf = np.nan  # if no misclassifications, return NaN\n",
    "        \n",
    "    # Compute average confidence for correctly classified samples:\n",
    "    correct_mask = preds == test_gdf['int_label'].values\n",
    "    if correct_mask.sum() > 0:\n",
    "        correct_confidences = [probs[i, preds[i]] for i in np.where(correct_mask)[0]]\n",
    "        avg_correct_conf = np.mean(correct_confidences)\n",
    "    else:\n",
    "        avg_correct_conf = np.nan  # if no correct classifications, return NaN\n",
    "    \n",
    "    meta_results_use_case.append({\n",
    "         \"model_name\": key[0],\n",
    "         \"meta_method\": f\"use_case_{key[1]}\",\n",
    "         \"test_macro_prec\": prec,\n",
    "         \"test_macro_rec\": rec,\n",
    "         \"test_macro_f1\": f1,\n",
    "         \"test_acc\": acc,\n",
    "         \"test_roc_auc\": roc_auc,\n",
    "         \"test_rmse\": rmse,\n",
    "         \"test_mae\": mae,\n",
    "         \"avg_misclassified_confidence\": avg_mis_conf,\n",
    "         \"avg_correct_confidence\": avg_correct_conf\n",
    "    })\n",
    "\n",
    "# Save the evaluation results and predictions\n",
    "meta_result_use_case_df: pd.DataFrame = pd.DataFrame.from_dict(meta_results_use_case)\n",
    "meta_result_use_case_df.to_csv(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learner_test_per_use_case.csv'), index=False)\n",
    "test_gdf.to_parquet(os.path.join(RESULTS_PATH, 'classif_head', 'meta_learning_preds_per_use_case.parquet'))\n",
    "\n",
    "meta_result_use_case_df\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
